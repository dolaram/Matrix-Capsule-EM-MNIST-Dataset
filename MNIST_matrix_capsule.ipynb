{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Capsule for MNIST image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from config import cfg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_routing = 2\n",
    "ac_lambda0 = 0.01, \n",
    "#'\\lambda in the activation function a_c, iteration 0')\n",
    "ac_lambda_step = 0.01,\n",
    "#'It is described that \\lambda increases at each iteration with a fixed schedule, however specific super parameters is absent.')\n",
    "epsilon = 1e-9\n",
    "\n",
    "batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "is_train = True\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_ent_loss(output, x, y):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=output)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    num_class = int(output.get_shape()[-1])\n",
    "    data_size = int(x.get_shape()[1])\n",
    "\n",
    "    # reconstruction loss\n",
    "    y = tf.one_hot(y, num_class, dtype=tf.float32)\n",
    "    y = tf.expand_dims(y, axis=2)\n",
    "    output = tf.expand_dims(output, axis=2)\n",
    "    output = tf.reshape(tf.multiply(output, y), shape=[cfg.batch_size, -1])\n",
    "    tf.logging.info(\"decoder input value dimension:{}\".format(output.get_shape()))\n",
    "\n",
    "    with tf.variable_scope('decoder'):\n",
    "        output = slim.fully_connected(output, 512, trainable=True)\n",
    "        output = slim.fully_connected(output, 1024, trainable=True)\n",
    "        output = slim.fully_connected(output, data_size * data_size,\n",
    "                                      trainable=True, activation_fn=tf.sigmoid)\n",
    "\n",
    "        x = tf.reshape(x, shape=[cfg.batch_size, -1])\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(output - x))\n",
    "\n",
    "    # regularization loss\n",
    "    regularization = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    # loss+0.0005*reconstruction_loss+regularization#\n",
    "    loss_all = tf.add_n([loss] + [0.0005 * reconstruction_loss] + regularization)\n",
    "\n",
    "    return loss_all, reconstruction_loss, output\n",
    "\n",
    "\n",
    "def spread_loss(output, pose_out, x, y, m):\n",
    "    \"\"\"\n",
    "    # check NaN\n",
    "    # See: https://stackoverflow.com/questions/40701712/how-to-check-nan-in-gradients-in-tensorflow-when-updating\n",
    "    output_check = [tf.check_numerics(output, message='NaN Found!')]\n",
    "    with tf.control_dependencies(output_check):\n",
    "    \"\"\"\n",
    "\n",
    "    num_class = int(output.get_shape()[-1])\n",
    "    data_size = int(x.get_shape()[1])\n",
    "\n",
    "    y = tf.one_hot(y, num_class, dtype=tf.float32)\n",
    "\n",
    "    # spread loss\n",
    "    output1 = tf.reshape(output, shape=[cfg.batch_size, 1, num_class])\n",
    "    y = tf.expand_dims(y, axis=2)\n",
    "    at = tf.matmul(output1, y)\n",
    "    \"\"\"Paper eq(5).\"\"\"\n",
    "    loss = tf.square(tf.maximum(0., m - (at - output1)))\n",
    "    loss = tf.matmul(loss, 1. - y)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    # reconstruction loss\n",
    "    # pose_out = tf.reshape(tf.matmul(pose_out, y, transpose_a=True), shape=[cfg.batch_size, -1])\n",
    "    pose_out = tf.reshape(tf.multiply(pose_out, y), shape=[cfg.batch_size, -1])\n",
    "    tf.logging.info(\"decoder input value dimension:{}\".format(pose_out.get_shape()))\n",
    "\n",
    "    with tf.variable_scope('decoder'):\n",
    "        pose_out = slim.fully_connected(pose_out, 512, trainable=True, weights_regularizer=tf.contrib.layers.l2_regularizer(5e-04))\n",
    "        pose_out = slim.fully_connected(pose_out, 1024, trainable=True, weights_regularizer=tf.contrib.layers.l2_regularizer(5e-04))\n",
    "        pose_out = slim.fully_connected(pose_out, data_size * data_size,\n",
    "                                        trainable=True, activation_fn=tf.sigmoid, weights_regularizer=tf.contrib.layers.l2_regularizer(5e-04))\n",
    "\n",
    "        x = tf.reshape(x, shape=[cfg.batch_size, -1])\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(pose_out - x))\n",
    "\n",
    "    if cfg.weight_reg:\n",
    "        # regularization loss\n",
    "        regularization = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        # loss+0.0005*reconstruction_loss+regularization#\n",
    "        loss_all = tf.add_n([loss] + [0.0005 * data_size* data_size * reconstruction_loss] + regularization)\n",
    "    else:\n",
    "        loss_all = tf.add_n([loss] + [0.0005 * data_size* data_size * reconstruction_loss])\n",
    "\n",
    "    return loss_all, loss, reconstruction_loss, pose_out\n",
    "\n",
    "# input should be a tensor with size as [batch_size, height, width, channels]\n",
    "\n",
    "\n",
    "def kernel_tile(input, kernel, stride):\n",
    "    # output = tf.extract_image_patches(input, ksizes=[1, kernel, kernel, 1], strides=[1, stride, stride, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    input_shape = input.get_shape()\n",
    "    tile_filter = np.zeros(shape=[kernel, kernel, input_shape[3],\n",
    "                                  kernel * kernel], dtype=np.float32)\n",
    "    for i in range(kernel):\n",
    "        for j in range(kernel):\n",
    "            tile_filter[i, j, :, i * kernel + j] = 1.0\n",
    "\n",
    "    tile_filter_op = tf.constant(tile_filter, dtype=tf.float32)\n",
    "    output = tf.nn.depthwise_conv2d(input, tile_filter_op, strides=[\n",
    "                                    1, stride, stride, 1], padding='VALID')\n",
    "    output_shape = output.get_shape()\n",
    "    output = tf.reshape(output, shape=[int(output_shape[0]), int(\n",
    "        output_shape[1]), int(output_shape[2]), int(input_shape[3]), kernel * kernel])\n",
    "    output = tf.transpose(output, perm=[0, 1, 2, 4, 3])\n",
    "\n",
    "    return output\n",
    "\n",
    "# input should be a tensor with size as [batch_size, caps_num_i, 16]\n",
    "def mat_transform(input, caps_num_c, regularizer, tag=False):\n",
    "    batch_size = int(input.get_shape()[0])\n",
    "    caps_num_i = int(input.get_shape()[1])\n",
    "    output = tf.reshape(input, shape=[batch_size, caps_num_i, 1, 4, 4])\n",
    "    # the output of capsule is miu, the mean of a Gaussian, and activation, the sum of probabilities\n",
    "    # it has no relationship with the absolute values of w and votes\n",
    "    # using weights with bigger stddev helps numerical stability\n",
    "    w = slim.variable('w', shape=[1, caps_num_i, caps_num_c, 4, 4], dtype=tf.float32,\n",
    "                      initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1.0),\n",
    "                      regularizer=regularizer)\n",
    "\n",
    "    w = tf.tile(w, [batch_size, 1, 1, 1, 1])\n",
    "    output = tf.tile(output, [1, 1, caps_num_c, 1, 1])\n",
    "    votes = tf.reshape(tf.matmul(output, w), [batch_size, caps_num_i, caps_num_c, 16])\n",
    "\n",
    "    return votes\n",
    "\n",
    "\n",
    "def build_arch_baseline(input, is_train: bool, num_classes: int):\n",
    "\n",
    "    bias_initializer = tf.truncated_normal_initializer(\n",
    "        mean=0.0, stddev=0.01)  # tf.constant_initializer(0.0)\n",
    "    # The paper didnot mention any regularization, a common l2 regularizer to weights is added here\n",
    "    weights_regularizer = tf.contrib.layers.l2_regularizer(5e-04)\n",
    "\n",
    "    tf.logging.info('input shape: {}'.format(input.get_shape()))\n",
    "\n",
    "    # weights_initializer=initializer,\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected], trainable=is_train, biases_initializer=bias_initializer, weights_regularizer=weights_regularizer):\n",
    "        with tf.variable_scope('relu_conv1') as scope:\n",
    "            output = slim.conv2d(input, num_outputs=32, kernel_size=[\n",
    "                                 5, 5], stride=1, padding='SAME', scope=scope, activation_fn=tf.nn.relu)\n",
    "            output = slim.max_pool2d(output, [2, 2], scope='max_2d_layer1')\n",
    "\n",
    "            tf.logging.info('output shape: {}'.format(output.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('relu_conv2') as scope:\n",
    "            output = slim.conv2d(output, num_outputs=64, kernel_size=[\n",
    "                                 5, 5], stride=1, padding='SAME', scope=scope, activation_fn=tf.nn.relu)\n",
    "            output = slim.max_pool2d(output, [2, 2], scope='max_2d_layer2')\n",
    "\n",
    "            tf.logging.info('output shape: {}'.format(output.get_shape()))\n",
    "\n",
    "        output = slim.flatten(output)\n",
    "        output = slim.fully_connected(output, 1024, scope='relu_fc3', activation_fn=tf.nn.relu)\n",
    "        tf.logging.info('output shape: {}'.format(output.get_shape()))\n",
    "        output = slim.dropout(output, 0.5, scope='dp')\n",
    "        output = slim.fully_connected(output, num_classes, scope='final_layer', activation_fn=None)\n",
    "        tf.logging.info('output shape: {}'.format(output.get_shape()))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_routing(votes, activation, caps_num_c, regularizer, tag=False):\n",
    "    test = []\n",
    "\n",
    "    batch_size = int(votes.get_shape()[0])\n",
    "    caps_num_i = int(activation.get_shape()[1])\n",
    "    n_channels = int(votes.get_shape()[-1])\n",
    "\n",
    "    sigma_square = []\n",
    "    miu = []\n",
    "    activation_out = []\n",
    "    beta_v = slim.variable('beta_v', shape=[caps_num_c, n_channels], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0),#tf.truncated_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                           regularizer=regularizer)\n",
    "    beta_a = slim.variable('beta_a', shape=[caps_num_c], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0),#tf.truncated_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                           regularizer=regularizer)\n",
    "\n",
    "    # votes_in = tf.stop_gradient(votes, name='stop_gradient_votes')\n",
    "    # activation_in = tf.stop_gradient(activation, name='stop_gradient_activation')\n",
    "    votes_in = votes\n",
    "    activation_in = activation\n",
    "\n",
    "    for iters in range(iter_routing):\n",
    "        # if iters == cfg.iter_routing-1:\n",
    "\n",
    "        # e-step\n",
    "        if iters == 0:\n",
    "            r = tf.constant(np.ones([batch_size, caps_num_i, caps_num_c], dtype=np.float32) / caps_num_c)\n",
    "        else:\n",
    "            # Contributor: Yunzhi Shi\n",
    "            # log and exp here provide higher numerical stability especially for bigger number of iterations\n",
    "            log_p_c_h = -tf.log(tf.sqrt(sigma_square)) - \\\n",
    "                        (tf.square(votes_in - miu) / (2 * sigma_square))\n",
    "            log_p_c_h = log_p_c_h - \\\n",
    "                        (tf.reduce_max(log_p_c_h, axis=[2, 3], keep_dims=True) - tf.log(10.0))\n",
    "            p_c = tf.exp(tf.reduce_sum(log_p_c_h, axis=3))\n",
    "\n",
    "            ap = p_c * tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            # ap = tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            r = ap / (tf.reduce_sum(ap, axis=2, keepdims=True) + epsilon)\n",
    "\n",
    "        # m-step\n",
    "        r = r * activation_in\n",
    "        r = r / (tf.reduce_sum(r, axis=2, keepdims=True)+epsilon)\n",
    "\n",
    "        r_sum = tf.reduce_sum(r, axis=1, keepdims=True)\n",
    "        r1 = tf.reshape(r / (r_sum + epsilon),\n",
    "                        shape=[batch_size, caps_num_i, caps_num_c, 1])\n",
    "\n",
    "        miu = tf.reduce_sum(votes_in * r1, axis=1, keepdims=True)\n",
    "        sigma_square = tf.reduce_sum(tf.square(votes_in - miu) * r1,\n",
    "                                     axis=1, keepdims=True) + epsilon\n",
    "\n",
    "        if iters == iter_routing-1:\n",
    "            r_sum = tf.reshape(r_sum, [batch_size, caps_num_c, 1])\n",
    "            cost_h = (beta_v + tf.log(tf.sqrt(tf.reshape(sigma_square,\n",
    "                                                         shape=[batch_size, caps_num_c, n_channels])))) * r_sum\n",
    "\n",
    "            activation_out = tf.nn.softmax(ac_lambda0 * (beta_a - tf.reduce_sum(cost_h, axis=2)))\n",
    "        else:\n",
    "            activation_out = tf.nn.softmax(r_sum)\n",
    "        # if iters <= cfg.iter_routing-1:\n",
    "        #     activation_out = tf.stop_gradient(activation_out, name='stop_gradient_activation')\n",
    "\n",
    "    return miu, activation_out, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_add(dataset_name: str):\n",
    "    import numpy as np\n",
    "    # TODO: get coord add for cifar10/100 datasets (32x32x3)\n",
    "    options = {'mnist': ([[[8., 8.], [12., 8.], [16., 8.]],\n",
    "                          [[8., 12.], [12., 12.], [16., 12.]],\n",
    "                          [[8., 16.], [12., 16.], [16., 16.]]], 28.),\n",
    "               'smallNORB': ([[[8., 8.], [12., 8.], [16., 8.], [24., 8.]],\n",
    "                              [[8., 12.], [12., 12.], [16., 12.], [24., 12.]],\n",
    "                              [[8., 16.], [12., 16.], [16., 16.], [24., 16.]],\n",
    "                              [[8., 24.], [12., 24.], [16., 24.], [24., 24.]]], 32.)\n",
    "               }\n",
    "    coord_add, scale = options[dataset_name]\n",
    "\n",
    "    coord_add = np.array(coord_add, dtype=np.float32) / scale\n",
    "\n",
    "    return coord_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coord_add = get_coord_add('mnist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_routing = 2\n",
    "ac_lambda0 = 0.01, \n",
    "#'\\lambda in the activation function a_c, iteration 0')\n",
    "ac_lambda_step = 0.01,\n",
    "#'It is described that \\lambda increases at each iteration with a fixed schedule, however specific super parameters is absent.')\n",
    "epsilon = 1e-9\n",
    "\n",
    "batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "is_train = True\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixCapsule(object):\n",
    "    def __init__(self, is_train=True):\n",
    "        tf.reset_default_graph()\n",
    "        self.graph = tf.Graph()\n",
    "        self._build_arch()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        print(\"Graph for Matrix Capsule is ready for training\")\n",
    "    def _build_arch(self):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(batch_size, 28, 28, 1))\n",
    "        self.Y = tf.placeholder(tf.float32, [batch_size, 10])\n",
    "        data_size = int(self.X.get_shape()[1])\n",
    "        # xavier initialization is necessary here to provide higher stability\n",
    "        initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n",
    "        # instead of initializing bias with constant 0, \n",
    "        # a truncated normal initializer is exploited here for higher stability \n",
    "        bias_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)  # tf.constant_initializer(0.0)\n",
    "        # The paper didnot mention any regularization, a common l2 regularizer to weights is added here\n",
    "        weights_regularizer = tf.contrib.layers.l2_regularizer(5e-04)\n",
    "        # weights_initializer=initializer,\n",
    "        with slim.arg_scope([slim.conv2d], trainable=is_train, biases_initializer=bias_initializer, weights_regularizer=weights_regularizer):\n",
    "            with tf.variable_scope('relu_conv1'):\n",
    "                output = slim.conv2d(self.X, num_outputs=A, kernel_size=[5, 5], stride=2, padding='VALID', scope='relu_conv1', activation_fn=tf.nn.relu)\n",
    "                data_size = int(np.floor((data_size - 4) / 2))\n",
    "                #print(output.get_shape())\n",
    "                #print(data_size)\n",
    "                a = [batch_size, data_size, data_size, 32]\n",
    "                #print(a)\n",
    "                assert output.get_shape() == [batch_size, data_size, data_size, 32]\n",
    "            with tf.variable_scope('primary_caps'):\n",
    "                pose = slim.conv2d(output, num_outputs=B * 16,kernel_size=[1, 1], stride=1, padding='VALID', scope='primary_caps', activation_fn=None)\n",
    "                activation = slim.conv2d(output, num_outputs=B, kernel_size=[\n",
    "                                         1, 1], stride=1, padding='VALID', scope='primary_caps/activation', activation_fn=tf.nn.sigmoid)\n",
    "                pose = tf.reshape(pose, shape=[batch_size, data_size, data_size, B, 16])\n",
    "                activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, B, 1])\n",
    "                output = tf.concat([pose, activation], axis=4)\n",
    "                output = tf.reshape(output, shape=[batch_size, data_size, data_size, -1])\n",
    "                assert output.get_shape() == [batch_size, data_size, data_size, B * 17]\n",
    "\n",
    "            with tf.variable_scope('conv_caps1') as scope:\n",
    "                output = kernel_tile(output, 3, 2)\n",
    "                data_size = int(np.floor((data_size - 2) / 2))\n",
    "                output = tf.reshape(output, shape=[batch_size *\n",
    "                                                   data_size * data_size, 3 * 3 * B, 17])\n",
    "                activation = tf.reshape(output[:, :, 16], shape=[\n",
    "                                        batch_size * data_size * data_size, 3 * 3 * B, 1])\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(output[:, :, :16], C, weights_regularizer, tag=True)\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    miu, activation, _ = em_routing(votes, activation, C, weights_regularizer)\n",
    "                pose = tf.reshape(miu, shape=[batch_size, data_size, data_size, C, 16])\n",
    "                activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, C, 1])\n",
    "                output = tf.reshape(tf.concat([pose, activation], axis=4),[batch_size, data_size, data_size, -1])\n",
    "                #print(output.get_shape())\n",
    "            with tf.variable_scope('conv_caps2') as scope:\n",
    "                output = kernel_tile(output, 3, 1)\n",
    "                data_size = int(np.floor((data_size - 2) / 1))\n",
    "                output = tf.reshape(output, shape=[batch_size * data_size * data_size, 3 * 3 * C, 17])\n",
    "                activation = tf.reshape(output[:, :, 16], shape=[batch_size * data_size * data_size, 3 * 3 * C, 1])\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(output[:, :, :16], D, weights_regularizer)\n",
    "                    #tf.logging.info('conv cap 2 votes shape: {}'.format(votes.get_shape()))\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    miu, activation, _ = em_routing(votes, activation, D, weights_regularizer)\n",
    "                pose = tf.reshape(miu, shape=[batch_size * data_size * data_size, D, 16])\n",
    "                #tf.logging.info('conv cap 2 pose shape: {}'.format(votes.get_shape()))\n",
    "                activation = tf.reshape(activation, shape=[batch_size * data_size * data_size, D, 1])\n",
    "                #tf.logging.info('conv cap 2 activation shape: {}'.format(activation.get_shape()))\n",
    "                # It is not clear from the paper that ConvCaps2 is full connected to Class Capsules,\n",
    "                #or is conv connected with kernel size of 1*1 and a global average pooling.\n",
    "                # From the description in Figure 1 of the paper and the amount of parameters \n",
    "                #(310k in the paper and 316,853 in fact), I assume a conv cap plus a golbal average pooling is the design.\n",
    "            with tf.variable_scope('class_caps') as scope:\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(pose, num_classes, weights_regularizer)\n",
    "\n",
    "                    assert votes.get_shape() == [batch_size * data_size * data_size, D, num_classes, 16]\n",
    "                    #tf.logging.info('class cap votes original shape: {}'.format(votes.get_shape()))\n",
    "                    coord_add = get_coord_add('mnist') \n",
    "                    coord_add = np.reshape(coord_add, newshape=[data_size * data_size, 1, 1, 2])\n",
    "                    coord_add = np.tile(coord_add, [batch_size, D, num_classes, 1])\n",
    "                    coord_add_op = tf.constant(coord_add, dtype=tf.float32)\n",
    "\n",
    "                    votes = tf.concat([coord_add_op, votes], axis=3)\n",
    "                    #tf.logging.info('class cap votes coord add shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    miu, activation, test2 = em_routing(votes, activation, num_classes, weights_regularizer)\n",
    "                    #tf.logging.info('class cap activation shape: {}'.format(activation.get_shape()))\n",
    "                    #tf.summary.histogram(name=\"class_cap_routing_hist\", values=test2)\n",
    "\n",
    "                output = tf.reshape(activation, shape=[batch_size, data_size, data_size, num_classes])\n",
    "            output = tf.reshape(tf.nn.avg_pool(output, ksize=[1, data_size, data_size, 1], strides=[\n",
    "                        1, 1, 1, 1], padding='VALID'), shape=[batch_size, num_classes])\n",
    "            #tf.logging.info('class cap output shape: {}'.format(output.get_shape()))\n",
    "\n",
    "            pose = tf.nn.avg_pool(tf.reshape(miu, shape=[batch_size, data_size, data_size, -1]), ksize=[\n",
    "                                  1, data_size, data_size, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "            pose_out = tf.reshape(pose, shape=[batch_size, num_classes, 18])\n",
    "            vector_j = tf.reshape(pose_out, shape= [-1, num_classes * 18])\n",
    "            #print(\"output_size\",pose_out.get_shape())\n",
    "            #print(\"output_size\",vector_j.get_shape())\n",
    "            \n",
    "            with tf.variable_scope('output_layer') as scope:\n",
    "                self.logits = tf.contrib.layers.fully_connected(vector_j, num_outputs=10, activation_fn=None)\n",
    "                \n",
    "        with tf.variable_scope('loss') as scope:\n",
    "            self.cross_entropy_loss = tf.losses.softmax_cross_entropy(self.Y, self.logits)\n",
    "            #print(\"output_size\",self.logits.get_shape())\n",
    "            \n",
    "        with tf.variable_scope('optimizer') as scope:\n",
    "            self.train_op = tf.train.AdamOptimizer(1e-3).minimize(self.cross_entropy_loss)\n",
    "            \n",
    "        with tf.variable_scope('prediction') as scope:  \n",
    "            prediction = tf.nn.softmax(self.logits,-1)\n",
    "            self.y_hat = tf.to_int32(tf.argmax(prediction, axis=1))\n",
    "        \n",
    "        with tf.variable_scope('acc'):\n",
    "            self.labels = tf.to_int32(tf.argmax(self.Y, axis=1))\n",
    "            correct_prediction = tf.equal(tf.to_int32(self.labels), self.y_hat)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n",
    "        #print(self.accuracy) \n",
    "    def train(self, batch_xs, batch_ys):\n",
    "        _,loss,acc = self.sess.run([self.train_op,self.cross_entropy_loss, self.accuracy],feed_dict={self.X: batch_xs, self.Y: batch_ys})\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_itrs=50*55000/50\n",
    "n_itrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-d3318b03a502>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/cnn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/cnn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/cnn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/cnn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/cnn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-5-86b07528d84b>:35: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Graph for Matrix Capsule is ready for training\n",
      "session started\n",
      "0\n",
      "step-0 summary: loss= 2.3272855281829834, training accuracy = 6.0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "step-5 summary: loss= 2.3497073650360107, training accuracy = 6.0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "n_itrs = 7\n",
    "model = MatrixCapsule()\n",
    "print(\"session started\")\n",
    "\n",
    "n_itrs = 1000\n",
    "for step in range(n_itrs):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    batch_xs = batch_xs.reshape(batch_size, 28, 28,1)\n",
    "    batch_ys = batch_ys.reshape(batch_size, 10)\n",
    "    loss, acc =  model.train(batch_xs,batch_ys)\n",
    "    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
    "    print(step)\n",
    "    if (step % 30 == 0):\n",
    "        print(\"step-{} summary: loss= {}, training accuracy = {}\".format(step, loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"acc/mul:0\", shape=(), dtype=float32)\n",
      "Graph for Matrix Capsule is ready for training\n"
     ]
    }
   ],
   "source": [
    "MC = MatrixCapsule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "tf.reset_default_graph()\n",
    "input = tf.placeholder(tf.float32, shape=(50, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_train = True\n",
    "num_classes = 10\n",
    "test1 = []\n",
    "data_size = int(input.get_shape()[1])\n",
    "print(data_size)\n",
    "# xavier initialization is necessary here to provide higher stability\n",
    "# initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n",
    "# instead of initializing bias with constant 0, a truncated normal initializer is exploited here for higher stability\n",
    "bias_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)  # tf.constant_initializer(0.0)\n",
    "# The paper didnot mention any regularization, a common l2 regularizer to weights is added here\n",
    "weights_regularizer = tf.contrib.layers.l2_regularizer(5e-04)\n",
    "# weights_initializer=initializer,\n",
    "with slim.arg_scope([slim.conv2d], trainable=is_train, biases_initializer=bias_initializer, weights_regularizer=weights_regularizer):\n",
    "    with tf.variable_scope('relu_conv1'):\n",
    "        output = slim.conv2d(input, num_outputs=A, kernel_size=[5, 5], stride=2, padding='VALID', scope='relu_conv1', activation_fn=tf.nn.relu)\n",
    "        data_size = int(np.floor((data_size - 4) / 2))\n",
    "        print(output.get_shape())\n",
    "        print(data_size)\n",
    "        a = [batch_size, data_size, data_size, 32]\n",
    "        print(a)\n",
    "        assert output.get_shape() == [batch_size, data_size, data_size, 32]\n",
    "    with tf.variable_scope('primary_caps'):\n",
    "        pose = slim.conv2d(output, num_outputs=B * 16,kernel_size=[1, 1], stride=1, padding='VALID', scope='primary_caps', activation_fn=None)\n",
    "        activation = slim.conv2d(output, num_outputs=B, kernel_size=[\n",
    "                                 1, 1], stride=1, padding='VALID', scope='primary_caps/activation', activation_fn=tf.nn.sigmoid)\n",
    "        pose = tf.reshape(pose, shape=[batch_size, data_size, data_size, B, 16])\n",
    "        activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, B, 1])\n",
    "        output = tf.concat([pose, activation], axis=4)\n",
    "        output = tf.reshape(output, shape=[batch_size, data_size, data_size, -1])\n",
    "        assert output.get_shape() == [batch_size, data_size, data_size, B * 17]\n",
    "    \n",
    "    with tf.variable_scope('conv_caps1') as scope:\n",
    "        output = kernel_tile(output, 3, 2)\n",
    "        data_size = int(np.floor((data_size - 2) / 2))\n",
    "        output = tf.reshape(output, shape=[batch_size *\n",
    "                                           data_size * data_size, 3 * 3 * B, 17])\n",
    "        activation = tf.reshape(output[:, :, 16], shape=[\n",
    "                                batch_size * data_size * data_size, 3 * 3 * B, 1])\n",
    "        with tf.variable_scope('v') as scope:\n",
    "            votes = mat_transform(output[:, :, :16], C, weights_regularizer, tag=True)\n",
    "        with tf.variable_scope('routing') as scope:\n",
    "            miu, activation, _ = em_routing(votes, activation, C, weights_regularizer)\n",
    "        pose = tf.reshape(miu, shape=[batch_size, data_size, data_size, C, 16])\n",
    "        activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, C, 1])\n",
    "        output = tf.reshape(tf.concat([pose, activation], axis=4),[batch_size, data_size, data_size, -1])\n",
    "        print(output.get_shape())\n",
    "    with tf.variable_scope('conv_caps2') as scope:\n",
    "        output = kernel_tile(output, 3, 1)\n",
    "        data_size = int(np.floor((data_size - 2) / 1))\n",
    "        output = tf.reshape(output, shape=[batch_size * data_size * data_size, 3 * 3 * C, 17])\n",
    "        activation = tf.reshape(output[:, :, 16], shape=[batch_size * data_size * data_size, 3 * 3 * C, 1])\n",
    "        with tf.variable_scope('v') as scope:\n",
    "            votes = mat_transform(output[:, :, :16], D, weights_regularizer)\n",
    "            #tf.logging.info('conv cap 2 votes shape: {}'.format(votes.get_shape()))\n",
    "        with tf.variable_scope('routing') as scope:\n",
    "            miu, activation, _ = em_routing(votes, activation, D, weights_regularizer)\n",
    "        pose = tf.reshape(miu, shape=[batch_size * data_size * data_size, D, 16])\n",
    "        #tf.logging.info('conv cap 2 pose shape: {}'.format(votes.get_shape()))\n",
    "        activation = tf.reshape(activation, shape=[batch_size * data_size * data_size, D, 1])\n",
    "        #tf.logging.info('conv cap 2 activation shape: {}'.format(activation.get_shape()))\n",
    "        # It is not clear from the paper that ConvCaps2 is full connected to Class Capsules,\n",
    "        #or is conv connected with kernel size of 1*1 and a global average pooling.\n",
    "        # From the description in Figure 1 of the paper and the amount of parameters \n",
    "        #(310k in the paper and 316,853 in fact), I assume a conv cap plus a golbal average pooling is the design.\n",
    "    with tf.variable_scope('class_caps') as scope:\n",
    "        with tf.variable_scope('v') as scope:\n",
    "            votes = mat_transform(pose, num_classes, weights_regularizer)\n",
    "\n",
    "            assert votes.get_shape() == [batch_size * data_size * data_size, D, num_classes, 16]\n",
    "            #tf.logging.info('class cap votes original shape: {}'.format(votes.get_shape()))\n",
    "            coord_add = get_coord_add('mnist') \n",
    "            coord_add = np.reshape(coord_add, newshape=[data_size * data_size, 1, 1, 2])\n",
    "            coord_add = np.tile(coord_add, [batch_size, D, num_classes, 1])\n",
    "            coord_add_op = tf.constant(coord_add, dtype=tf.float32)\n",
    "\n",
    "            votes = tf.concat([coord_add_op, votes], axis=3)\n",
    "            #tf.logging.info('class cap votes coord add shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('routing') as scope:\n",
    "            miu, activation, test2 = em_routing(votes, activation, num_classes, weights_regularizer)\n",
    "            #tf.logging.info('class cap activation shape: {}'.format(activation.get_shape()))\n",
    "            #tf.summary.histogram(name=\"class_cap_routing_hist\", values=test2)\n",
    "\n",
    "        output = tf.reshape(activation, shape=[batch_size, data_size, data_size, num_classes])\n",
    "\n",
    "    output = tf.reshape(tf.nn.avg_pool(output, ksize=[1, data_size, data_size, 1], strides=[\n",
    "                        1, 1, 1, 1], padding='VALID'), shape=[batch_size, num_classes])\n",
    "    #tf.logging.info('class cap output shape: {}'.format(output.get_shape()))\n",
    "\n",
    "    pose = tf.nn.avg_pool(tf.reshape(miu, shape=[batch_size, data_size, data_size, -1]), ksize=[\n",
    "                          1, data_size, data_size, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    pose_out = tf.reshape(pose, shape=[batch_size, num_classes, 18])\n",
    "    vector_j = tf.reshape(pose_out, shape= [-1, num_classes * 18])\n",
    "    print(\"output_size\",pose_out.get_shape())\n",
    "    print(\"output_size\",vector_j.get_shape())\n",
    "logits = tf.contrib.layers.fully_connected(vector_j, num_outputs=10, activation_fn=None)\n",
    "\n",
    "cross_entropy_loss = tf.losses.softmax_cross_entropy(y,logits)\n",
    "    \n",
    "print(\"output_size\",logits.get_shape())\n",
    "prediction = tf.nn.softmax(logits,-1)\n",
    "y_hat = tf.to_int32(tf.argmax(prediction, axis=1))\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy_loss)\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "print(y_hat)\n",
    "print(y)'''\n",
    "a=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65720\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    #print(shape)\n",
    "    #print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        #print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "tf.reset_default_graph()\n",
    "input = tf.placeholder(tf.float32, shape=(50, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_train = True\n",
    "num_classes = 10\n",
    "test1 = []\n",
    "data_size = int(input.get_shape()[1])\n",
    "print(data_size)\n",
    "# xavier initialization is necessary here to provide higher stability\n",
    "# initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n",
    "# instead of initializing bias with constant 0, a truncated normal initializer is exploited here for higher stability\n",
    "bias_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)  # tf.constant_initializer(0.0)\n",
    "# The paper didnot mention any regularization, a common l2 regularizer to weights is added here\n",
    "weights_regularizer = tf.contrib.layers.l2_regularizer(5e-04)\n",
    "# weights_initializer=initializer,\n",
    "with slim.arg_scope([slim.conv2d], trainable=is_train, biases_initializer=bias_initializer, weights_regularizer=weights_regularizer):\n",
    "    with tf.variable_scope('relu_conv1'):\n",
    "        output = slim.conv2d(input, num_outputs=A, kernel_size=[5, 5], stride=2, padding='VALID', scope='relu_conv1', activation_fn=tf.nn.relu)\n",
    "        data_size = int(np.floor((data_size - 4) / 2))\n",
    "        print(output.get_shape())\n",
    "        print(data_size)\n",
    "        a = [batch_size, data_size, data_size, 32]\n",
    "        print(a)\n",
    "        assert output.get_shape() == [batch_size, data_size, data_size, 32]\n",
    "    with tf.variable_scope('primary_caps'):\n",
    "        pose = slim.conv2d(output, num_outputs=B * 16,kernel_size=[1, 1], stride=1, padding='VALID', scope='primary_caps', activation_fn=None)\n",
    "        activation = slim.conv2d(output, num_outputs=B, kernel_size=[\n",
    "                                 1, 1], stride=1, padding='VALID', scope='primary_caps/activation', activation_fn=tf.nn.sigmoid)\n",
    "        pose = tf.reshape(pose, shape=[batch_size, data_size, data_size, B, 16])\n",
    "        activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, B, 1])\n",
    "        output = tf.concat([pose, activation], axis=4)\n",
    "        output = tf.reshape(output, shape=[batch_size, data_size, data_size, -1])\n",
    "        assert output.get_shape() == [batch_size, data_size, data_size, B * 17]\n",
    "    \n",
    "    with tf.variable_scope('conv_caps1') as scope:\n",
    "        output = kernel_tile(output, 3, 2)\n",
    "        data_size = int(np.floor((data_size - 2) / 2))\n",
    "        output = tf.reshape(output, shape=[batch_size *\n",
    "                                           data_size * data_size, 3 * 3 * B, 17])\n",
    "        activation = tf.reshape(output[:, :, 16], shape=[\n",
    "                                batch_size * data_size * data_size, 3 * 3 * B, 1])\n",
    "        with tf.variable_scope('v') as scope:\n",
    "            votes = mat_transform(output[:, :, :16], C, weights_regularizer, tag=True)\n",
    "        with tf.variable_scope('routing') as scope:\n",
    "            miu, activation, _ = em_routing(votes, activation, C, weights_regularizer)\n",
    "        pose = tf.reshape(miu, shape=[batch_size, data_size, data_size, C, 16])\n",
    "        activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, C, 1])\n",
    "        output = tf.reshape(tf.concat([pose, activation], axis=4),[batch_size, data_size, data_size, -1])\n",
    "        print(output.get_shape())\n",
    "    with tf.variable_scope('conv_caps2') as scope:\n",
    "        output = kernel_tile(output, 3, 1)\n",
    "        data_size = int(np.floor((data_size - 2) / 1))\n",
    "        output = tf.reshape(output, shape=[batch_size * data_size * data_size, 3 * 3 * C, 17])\n",
    "        activation = tf.reshape(output[:, :, 16], shape=[batch_size * data_size * data_size, 3 * 3 * C, 1])\n",
    "        with tf.variable_scope('v') as scope:\n",
    "            votes = mat_transform(output[:, :, :16], D, weights_regularizer)\n",
    "            #tf.logging.info('conv cap 2 votes shape: {}'.format(votes.get_shape()))\n",
    "        with tf.variable_scope('routing') as scope:\n",
    "            miu, activation, _ = em_routing(votes, activation, D, weights_regularizer)\n",
    "        pose = tf.reshape(miu, shape=[batch_size * data_size * data_size, D, 16])\n",
    "        #tf.logging.info('conv cap 2 pose shape: {}'.format(votes.get_shape()))\n",
    "        activation = tf.reshape(activation, shape=[batch_size * data_size * data_size, D, 1])\n",
    "        #tf.logging.info('conv cap 2 activation shape: {}'.format(activation.get_shape()))\n",
    "        # It is not clear from the paper that ConvCaps2 is full connected to Class Capsules,\n",
    "        #or is conv connected with kernel size of 1*1 and a global average pooling.\n",
    "        # From the description in Figure 1 of the paper and the amount of parameters \n",
    "        #(310k in the paper and 316,853 in fact), I assume a conv cap plus a golbal average pooling is the design.\n",
    "    with tf.variable_scope('class_caps') as scope:\n",
    "        with tf.variable_scope('v') as scope:\n",
    "            votes = mat_transform(pose, num_classes, weights_regularizer)\n",
    "\n",
    "            assert votes.get_shape() == [batch_size * data_size * data_size, D, num_classes, 16]\n",
    "            #tf.logging.info('class cap votes original shape: {}'.format(votes.get_shape()))\n",
    "            coord_add = get_coord_add('mnist') \n",
    "            coord_add = np.reshape(coord_add, newshape=[data_size * data_size, 1, 1, 2])\n",
    "            coord_add = np.tile(coord_add, [batch_size, D, num_classes, 1])\n",
    "            coord_add_op = tf.constant(coord_add, dtype=tf.float32)\n",
    "\n",
    "            votes = tf.concat([coord_add_op, votes], axis=3)\n",
    "            #tf.logging.info('class cap votes coord add shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('routing') as scope:\n",
    "            miu, activation, test2 = em_routing(votes, activation, num_classes, weights_regularizer)\n",
    "            #tf.logging.info('class cap activation shape: {}'.format(activation.get_shape()))\n",
    "            #tf.summary.histogram(name=\"class_cap_routing_hist\", values=test2)\n",
    "\n",
    "        output = tf.reshape(activation, shape=[batch_size, data_size, data_size, num_classes])\n",
    "\n",
    "    output = tf.reshape(tf.nn.avg_pool(output, ksize=[1, data_size, data_size, 1], strides=[\n",
    "                        1, 1, 1, 1], padding='VALID'), shape=[batch_size, num_classes])\n",
    "    #tf.logging.info('class cap output shape: {}'.format(output.get_shape()))\n",
    "\n",
    "    pose = tf.nn.avg_pool(tf.reshape(miu, shape=[batch_size, data_size, data_size, -1]), ksize=[\n",
    "                          1, data_size, data_size, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    pose_out = tf.reshape(pose, shape=[batch_size, num_classes, 18])\n",
    "    vector_j = tf.reshape(pose_out, shape= [-1, num_classes * 18])\n",
    "    print(\"output_size\",pose_out.get_shape())\n",
    "    print(\"output_size\",vector_j.get_shape())\n",
    "logits = tf.contrib.layers.fully_connected(vector_j, num_outputs=10, activation_fn=None)\n",
    "\n",
    "cross_entropy_loss = tf.losses.softmax_cross_entropy(y,logits)\n",
    "    \n",
    "print(\"output_size\",logits.get_shape())\n",
    "prediction = tf.nn.softmax(logits,-1)\n",
    "y_hat = tf.to_int32(tf.argmax(prediction, axis=1))\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy_loss)\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "print(y_hat)\n",
    "print(y)\n",
    "'''\n",
    "original = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
