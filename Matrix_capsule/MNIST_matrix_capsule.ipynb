{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Capsule for MNIST image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cn1lab005/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "# from config import cfg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_routing = 2\n",
    "ac_lambda0 = 0.01, \n",
    "#'\\lambda in the activation function a_c, iteration 0')\n",
    "ac_lambda_step = 0.01,\n",
    "#'It is described that \\lambda increases at each iteration with a fixed schedule, however specific super parameters is absent.')\n",
    "epsilon = 1e-9\n",
    "\n",
    "batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "is_train = True\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_tile(input, kernel, stride):\n",
    "    # output = tf.extract_image_patches(input, ksizes=[1, kernel, kernel, 1], strides=[1, stride, stride, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    input_shape = input.get_shape()\n",
    "    tile_filter = np.zeros(shape=[kernel, kernel, input_shape[3],\n",
    "                                  kernel * kernel], dtype=np.float32)\n",
    "    for i in range(kernel):\n",
    "        for j in range(kernel):\n",
    "            tile_filter[i, j, :, i * kernel + j] = 1.0\n",
    "\n",
    "    tile_filter_op = tf.constant(tile_filter, dtype=tf.float32)\n",
    "    output = tf.nn.depthwise_conv2d(input, tile_filter_op, strides=[\n",
    "                                    1, stride, stride, 1], padding='VALID')\n",
    "    output_shape = output.get_shape()\n",
    "    output = tf.reshape(output, shape=[int(output_shape[0]), int(\n",
    "        output_shape[1]), int(output_shape[2]), int(input_shape[3]), kernel * kernel])\n",
    "    output = tf.transpose(output, perm=[0, 1, 2, 4, 3])\n",
    "\n",
    "    return output\n",
    "\n",
    "# input should be a tensor with size as [batch_size, caps_num_i, 16]\n",
    "def mat_transform(input, caps_num_c, regularizer, tag=False):\n",
    "    batch_size = int(input.get_shape()[0])\n",
    "    caps_num_i = int(input.get_shape()[1])\n",
    "    output = tf.reshape(input, shape=[batch_size, caps_num_i, 1, 4, 4])\n",
    "    # the output of capsule is miu, the mean of a Gaussian, and activation, the sum of probabilities\n",
    "    # it has no relationship with the absolute values of w and votes\n",
    "    # using weights with bigger stddev helps numerical stability\n",
    "    w = slim.variable('w', shape=[1, caps_num_i, caps_num_c, 4, 4], dtype=tf.float32,\n",
    "                      initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1.0),\n",
    "                      regularizer=regularizer)\n",
    "\n",
    "    w = tf.tile(w, [batch_size, 1, 1, 1, 1])\n",
    "    output = tf.tile(output, [1, 1, caps_num_c, 1, 1])\n",
    "    votes = tf.reshape(tf.matmul(output, w), [batch_size, caps_num_i, caps_num_c, 16])\n",
    "\n",
    "    return votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_routing(votes, activation, caps_num_c, regularizer, tag=False):\n",
    "    test = []\n",
    "\n",
    "    batch_size = int(votes.get_shape()[0])\n",
    "    caps_num_i = int(activation.get_shape()[1])\n",
    "    n_channels = int(votes.get_shape()[-1])\n",
    "\n",
    "    sigma_square = []\n",
    "    miu = []\n",
    "    activation_out = []\n",
    "    beta_v = slim.variable('beta_v', shape=[caps_num_c, n_channels], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0),#tf.truncated_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                           regularizer=regularizer)\n",
    "    beta_a = slim.variable('beta_a', shape=[caps_num_c], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0),#tf.truncated_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                           regularizer=regularizer)\n",
    "\n",
    "    # votes_in = tf.stop_gradient(votes, name='stop_gradient_votes')\n",
    "    # activation_in = tf.stop_gradient(activation, name='stop_gradient_activation')\n",
    "    votes_in = votes\n",
    "    activation_in = activation\n",
    "\n",
    "    for iters in range(iter_routing):\n",
    "        # if iters == cfg.iter_routing-1:\n",
    "\n",
    "        # e-step\n",
    "        if iters == 0:\n",
    "            r = tf.constant(np.ones([batch_size, caps_num_i, caps_num_c], dtype=np.float32) / caps_num_c)\n",
    "        else:\n",
    "            # Contributor: Yunzhi Shi\n",
    "            # log and exp here provide higher numerical stability especially for bigger number of iterations\n",
    "            log_p_c_h = -tf.log(tf.sqrt(sigma_square)) - \\\n",
    "                        (tf.square(votes_in - miu) / (2 * sigma_square))\n",
    "            log_p_c_h = log_p_c_h - \\\n",
    "                        (tf.reduce_max(log_p_c_h, axis=[2, 3], keep_dims=True) - tf.log(10.0))\n",
    "            p_c = tf.exp(tf.reduce_sum(log_p_c_h, axis=3))\n",
    "\n",
    "            ap = p_c * tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            # ap = tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            r = ap / (tf.reduce_sum(ap, axis=2, keepdims=True) + epsilon)\n",
    "\n",
    "        # m-step\n",
    "        r = r * activation_in\n",
    "        r = r / (tf.reduce_sum(r, axis=2, keepdims=True)+epsilon)\n",
    "\n",
    "        r_sum = tf.reduce_sum(r, axis=1, keepdims=True)\n",
    "        r1 = tf.reshape(r / (r_sum + epsilon),\n",
    "                        shape=[batch_size, caps_num_i, caps_num_c, 1])\n",
    "\n",
    "        miu = tf.reduce_sum(votes_in * r1, axis=1, keepdims=True)\n",
    "        sigma_square = tf.reduce_sum(tf.square(votes_in - miu) * r1,\n",
    "                                     axis=1, keepdims=True) + epsilon\n",
    "\n",
    "        if iters == iter_routing-1:\n",
    "            r_sum = tf.reshape(r_sum, [batch_size, caps_num_c, 1])\n",
    "            cost_h = (beta_v + tf.log(tf.sqrt(tf.reshape(sigma_square,\n",
    "                                                         shape=[batch_size, caps_num_c, n_channels])))) * r_sum\n",
    "\n",
    "            activation_out = tf.nn.softmax(ac_lambda0 * (beta_a - tf.reduce_sum(cost_h, axis=2)))\n",
    "        else:\n",
    "            activation_out = tf.nn.softmax(r_sum)\n",
    "        # if iters <= cfg.iter_routing-1:\n",
    "        #     activation_out = tf.stop_gradient(activation_out, name='stop_gradient_activation')\n",
    "\n",
    "    return miu, activation_out, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_add(dataset_name: str):\n",
    "    import numpy as np\n",
    "    # TODO: get coord add for cifar10/100 datasets (32x32x3)\n",
    "    options = {'mnist': ([[[8., 8.], [12., 8.], [16., 8.]],\n",
    "                          [[8., 12.], [12., 12.], [16., 12.]],\n",
    "                          [[8., 16.], [12., 16.], [16., 16.]]], 28.),\n",
    "               'smallNORB': ([[[8., 8.], [12., 8.], [16., 8.], [24., 8.]],\n",
    "                              [[8., 12.], [12., 12.], [16., 12.], [24., 12.]],\n",
    "                              [[8., 16.], [12., 16.], [16., 16.], [24., 16.]],\n",
    "                              [[8., 24.], [12., 24.], [16., 24.], [24., 24.]]], 32.)\n",
    "               }\n",
    "    coord_add, scale = options[dataset_name]\n",
    "\n",
    "    coord_add = np.array(coord_add, dtype=np.float32) / scale\n",
    "\n",
    "    return coord_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coord_add = get_coord_add('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_routing = 2\n",
    "ac_lambda0 = 0.01, \n",
    "#'\\lambda in the activation function a_c, iteration 0')\n",
    "ac_lambda_step = 0.01,\n",
    "#'It is described that \\lambda increases at each iteration with a fixed schedule, however specific super parameters is absent.')\n",
    "epsilon = 1e-9\n",
    "\n",
    "batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "is_train = True\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixCapsule(object):\n",
    "    def __init__(self, is_train=True):\n",
    "        tf.reset_default_graph()\n",
    "        self.graph = tf.Graph()\n",
    "        self._build_arch()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        print(\"Graph for Matrix Capsule is ready for training\")\n",
    "    def _build_arch(self):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(batch_size, 28, 28, 1))\n",
    "        self.Y = tf.placeholder(tf.float32, [batch_size, 10])\n",
    "        data_size = int(self.X.get_shape()[1])\n",
    "        # xavier initialization is necessary here to provide higher stability\n",
    "        initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n",
    "        # instead of initializing bias with constant 0, \n",
    "        # a truncated normal initializer is exploited here for higher stability \n",
    "        bias_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)  # tf.constant_initializer(0.0)\n",
    "        # The paper didnot mention any regularization, a common l2 regularizer to weights is added here\n",
    "        weights_regularizer = tf.contrib.layers.l2_regularizer(5e-04)\n",
    "        # weights_initializer=initializer,\n",
    "        with slim.arg_scope([slim.conv2d], trainable=is_train, biases_initializer=bias_initializer, weights_regularizer=weights_regularizer):\n",
    "            with tf.variable_scope('relu_conv1'):\n",
    "                output = slim.conv2d(self.X, num_outputs=A, kernel_size=[5, 5], stride=2, padding='VALID', scope='relu_conv1', activation_fn=tf.nn.relu)\n",
    "                data_size = int(np.floor((data_size - 4) / 2))\n",
    "                #print(output.get_shape())\n",
    "                #print(data_size)\n",
    "                a = [batch_size, data_size, data_size, 32]\n",
    "                #print(a)\n",
    "                assert output.get_shape() == [batch_size, data_size, data_size, 32]\n",
    "            with tf.variable_scope('primary_caps'):\n",
    "                pose = slim.conv2d(output, num_outputs=B * 16,kernel_size=[1, 1], stride=1, padding='VALID', scope='primary_caps', activation_fn=None)\n",
    "                activation = slim.conv2d(output, num_outputs=B, kernel_size=[\n",
    "                                         1, 1], stride=1, padding='VALID', scope='primary_caps/activation', activation_fn=tf.nn.sigmoid)\n",
    "                pose = tf.reshape(pose, shape=[batch_size, data_size, data_size, B, 16])\n",
    "                activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, B, 1])\n",
    "                output = tf.concat([pose, activation], axis=4)\n",
    "                output = tf.reshape(output, shape=[batch_size, data_size, data_size, -1])\n",
    "                assert output.get_shape() == [batch_size, data_size, data_size, B * 17]\n",
    "\n",
    "            with tf.variable_scope('conv_caps1') as scope:\n",
    "                output = kernel_tile(output, 3, 2)\n",
    "                data_size = int(np.floor((data_size - 2) / 2))\n",
    "                output = tf.reshape(output, shape=[batch_size *\n",
    "                                                   data_size * data_size, 3 * 3 * B, 17])\n",
    "                activation = tf.reshape(output[:, :, 16], shape=[\n",
    "                                        batch_size * data_size * data_size, 3 * 3 * B, 1])\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(output[:, :, :16], C, weights_regularizer, tag=True)\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    miu, activation, _ = em_routing(votes, activation, C, weights_regularizer)\n",
    "                pose = tf.reshape(miu, shape=[batch_size, data_size, data_size, C, 16])\n",
    "                activation = tf.reshape(activation, shape=[batch_size, data_size, data_size, C, 1])\n",
    "                output = tf.reshape(tf.concat([pose, activation], axis=4),[batch_size, data_size, data_size, -1])\n",
    "                #print(output.get_shape())\n",
    "            with tf.variable_scope('conv_caps2') as scope:\n",
    "                output = kernel_tile(output, 3, 1)\n",
    "                data_size = int(np.floor((data_size - 2) / 1))\n",
    "                output = tf.reshape(output, shape=[batch_size * data_size * data_size, 3 * 3 * C, 17])\n",
    "                activation = tf.reshape(output[:, :, 16], shape=[batch_size * data_size * data_size, 3 * 3 * C, 1])\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(output[:, :, :16], D, weights_regularizer)\n",
    "                    #tf.logging.info('conv cap 2 votes shape: {}'.format(votes.get_shape()))\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    miu, activation, _ = em_routing(votes, activation, D, weights_regularizer)\n",
    "                pose = tf.reshape(miu, shape=[batch_size * data_size * data_size, D, 16])\n",
    "                #tf.logging.info('conv cap 2 pose shape: {}'.format(votes.get_shape()))\n",
    "                activation = tf.reshape(activation, shape=[batch_size * data_size * data_size, D, 1])\n",
    "                #tf.logging.info('conv cap 2 activation shape: {}'.format(activation.get_shape()))\n",
    "                # It is not clear from the paper that ConvCaps2 is full connected to Class Capsules,\n",
    "                #or is conv connected with kernel size of 1*1 and a global average pooling.\n",
    "                # From the description in Figure 1 of the paper and the amount of parameters \n",
    "                #(310k in the paper and 316,853 in fact), I assume a conv cap plus a golbal average pooling is the design.\n",
    "            with tf.variable_scope('class_caps') as scope:\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(pose, num_classes, weights_regularizer)\n",
    "\n",
    "                    assert votes.get_shape() == [batch_size * data_size * data_size, D, num_classes, 16]\n",
    "                    #tf.logging.info('class cap votes original shape: {}'.format(votes.get_shape()))\n",
    "                    coord_add = get_coord_add('mnist') \n",
    "                    coord_add = np.reshape(coord_add, newshape=[data_size * data_size, 1, 1, 2])\n",
    "                    coord_add = np.tile(coord_add, [batch_size, D, num_classes, 1])\n",
    "                    coord_add_op = tf.constant(coord_add, dtype=tf.float32)\n",
    "\n",
    "                    votes = tf.concat([coord_add_op, votes], axis=3)\n",
    "                    #tf.logging.info('class cap votes coord add shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    miu, activation, test2 = em_routing(votes, activation, num_classes, weights_regularizer)\n",
    "                    #tf.logging.info('class cap activation shape: {}'.format(activation.get_shape()))\n",
    "                    #tf.summary.histogram(name=\"class_cap_routing_hist\", values=test2)\n",
    "\n",
    "                output = tf.reshape(activation, shape=[batch_size, data_size, data_size, num_classes])\n",
    "            output = tf.reshape(tf.nn.avg_pool(output, ksize=[1, data_size, data_size, 1], strides=[\n",
    "                        1, 1, 1, 1], padding='VALID'), shape=[batch_size, num_classes])\n",
    "            #tf.logging.info('class cap output shape: {}'.format(output.get_shape()))\n",
    "\n",
    "            pose = tf.nn.avg_pool(tf.reshape(miu, shape=[batch_size, data_size, data_size, -1]), ksize=[\n",
    "                                  1, data_size, data_size, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "            pose_out = tf.reshape(pose, shape=[batch_size, num_classes, 18])\n",
    "            vector_j = tf.reshape(pose_out, shape= [-1, num_classes * 18])\n",
    "            #print(\"output_size\",pose_out.get_shape())\n",
    "            #print(\"output_size\",vector_j.get_shape())\n",
    "            \n",
    "            with tf.variable_scope('output_layer') as scope:\n",
    "                self.logits = tf.contrib.layers.fully_connected(vector_j, num_outputs=10, activation_fn=None)\n",
    "                \n",
    "        with tf.variable_scope('loss') as scope:\n",
    "            self.cross_entropy_loss = tf.losses.softmax_cross_entropy(self.Y, self.logits)\n",
    "            #print(\"output_size\",self.logits.get_shape())\n",
    "            \n",
    "        with tf.variable_scope('optimizer') as scope:\n",
    "            self.train_op = tf.train.AdamOptimizer(1e-3).minimize(self.cross_entropy_loss)\n",
    "            \n",
    "        with tf.variable_scope('prediction') as scope:  \n",
    "            prediction = tf.nn.softmax(self.logits,-1)\n",
    "            self.y_hat = tf.to_int32(tf.argmax(prediction, axis=1))\n",
    "        \n",
    "        with tf.variable_scope('acc'):\n",
    "            self.labels = tf.to_int32(tf.argmax(self.Y, axis=1))\n",
    "            correct_prediction = tf.equal(tf.to_int32(self.labels), self.y_hat)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n",
    "        #print(self.accuracy) \n",
    "    def train(self, batch_xs, batch_ys):\n",
    "        _,loss,acc = self.sess.run([self.train_op,self.cross_entropy_loss, self.accuracy],feed_dict={self.X: batch_xs, self.Y: batch_ys})\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph for Matrix Capsule is ready for training\n",
      "session started\n",
      "step-0 summary: loss= 2.321852922439575, training accuracy = 10.0\n",
      "step-30 summary: loss= 2.297380208969116, training accuracy = 10.0\n",
      "step-60 summary: loss= 2.2551751136779785, training accuracy = 20.0\n",
      "step-90 summary: loss= 2.245563507080078, training accuracy = 10.0\n",
      "step-120 summary: loss= 2.2256546020507812, training accuracy = 16.0\n",
      "step-150 summary: loss= 2.1722209453582764, training accuracy = 14.0\n",
      "step-180 summary: loss= 2.173096179962158, training accuracy = 20.0\n",
      "step-210 summary: loss= 2.1672322750091553, training accuracy = 22.0\n",
      "step-240 summary: loss= 2.112356424331665, training accuracy = 16.0\n",
      "step-270 summary: loss= 2.090301990509033, training accuracy = 28.0\n",
      "step-300 summary: loss= 2.0366194248199463, training accuracy = 18.0\n",
      "step-330 summary: loss= 2.101517915725708, training accuracy = 16.0\n",
      "step-360 summary: loss= 1.9238295555114746, training accuracy = 42.0\n",
      "step-390 summary: loss= 1.9550189971923828, training accuracy = 34.0\n",
      "step-420 summary: loss= 2.032363176345825, training accuracy = 26.0\n",
      "step-450 summary: loss= 1.834982991218567, training accuracy = 48.0\n",
      "step-480 summary: loss= 1.9763706922531128, training accuracy = 40.0\n",
      "step-510 summary: loss= 1.976062297821045, training accuracy = 24.0\n",
      "step-540 summary: loss= 1.8411633968353271, training accuracy = 42.0\n",
      "step-570 summary: loss= 1.8027199506759644, training accuracy = 36.0\n",
      "step-600 summary: loss= 1.720173954963684, training accuracy = 48.0\n",
      "step-630 summary: loss= 1.8637911081314087, training accuracy = 50.0\n",
      "step-660 summary: loss= 1.8054509162902832, training accuracy = 46.0\n",
      "step-690 summary: loss= 1.7763465642929077, training accuracy = 52.0\n",
      "step-720 summary: loss= 1.5546902418136597, training accuracy = 54.000003814697266\n",
      "step-750 summary: loss= 1.5247044563293457, training accuracy = 56.0\n",
      "step-780 summary: loss= 1.3085622787475586, training accuracy = 60.000003814697266\n",
      "step-810 summary: loss= 1.531997799873352, training accuracy = 44.0\n",
      "step-840 summary: loss= 1.4693899154663086, training accuracy = 50.0\n",
      "step-870 summary: loss= 1.343965768814087, training accuracy = 64.0\n",
      "step-900 summary: loss= 1.219747543334961, training accuracy = 76.0\n",
      "step-930 summary: loss= 1.164980173110962, training accuracy = 68.0\n",
      "step-960 summary: loss= 1.202168583869934, training accuracy = 66.0\n",
      "step-990 summary: loss= 1.370484709739685, training accuracy = 66.0\n",
      "step-1020 summary: loss= 1.1637241840362549, training accuracy = 54.000003814697266\n",
      "step-1050 summary: loss= 1.0853431224822998, training accuracy = 56.0\n",
      "step-1080 summary: loss= 0.9601030349731445, training accuracy = 80.0\n",
      "step-1110 summary: loss= 0.9145257472991943, training accuracy = 74.0\n",
      "step-1140 summary: loss= 0.6178054809570312, training accuracy = 86.0\n",
      "step-1170 summary: loss= 0.9834347367286682, training accuracy = 72.0\n",
      "step-1200 summary: loss= 0.7525937557220459, training accuracy = 76.0\n",
      "step-1230 summary: loss= 0.7174862027168274, training accuracy = 76.0\n",
      "step-1260 summary: loss= 0.7274090647697449, training accuracy = 82.0\n",
      "step-1290 summary: loss= 0.688553512096405, training accuracy = 84.0\n",
      "step-1320 summary: loss= 0.5480764508247375, training accuracy = 84.0\n",
      "step-1350 summary: loss= 0.8548641204833984, training accuracy = 68.0\n",
      "step-1380 summary: loss= 0.5352299809455872, training accuracy = 86.0\n",
      "step-1410 summary: loss= 0.36960849165916443, training accuracy = 92.0\n",
      "step-1440 summary: loss= 0.38036975264549255, training accuracy = 92.0\n",
      "step-1470 summary: loss= 0.31855911016464233, training accuracy = 94.0\n",
      "step-1500 summary: loss= 0.5463515520095825, training accuracy = 78.0\n",
      "step-1530 summary: loss= 0.6579976677894592, training accuracy = 84.0\n",
      "step-1560 summary: loss= 0.40135112404823303, training accuracy = 86.0\n",
      "step-1590 summary: loss= 0.37965941429138184, training accuracy = 88.0\n",
      "step-1620 summary: loss= 0.6167702078819275, training accuracy = 84.0\n",
      "step-1650 summary: loss= 0.4853631854057312, training accuracy = 82.0\n",
      "step-1680 summary: loss= 0.49157923460006714, training accuracy = 84.0\n",
      "step-1710 summary: loss= 0.5334405303001404, training accuracy = 86.0\n",
      "step-1740 summary: loss= 0.4185463488101959, training accuracy = 84.0\n",
      "step-1770 summary: loss= 0.4542089104652405, training accuracy = 84.0\n",
      "step-1800 summary: loss= 0.35676348209381104, training accuracy = 88.0\n",
      "step-1830 summary: loss= 0.4391903579235077, training accuracy = 84.0\n",
      "step-1860 summary: loss= 0.27446287870407104, training accuracy = 94.0\n",
      "step-1890 summary: loss= 0.4891645610332489, training accuracy = 88.0\n",
      "step-1920 summary: loss= 0.29018232226371765, training accuracy = 88.0\n",
      "step-1950 summary: loss= 0.5546421408653259, training accuracy = 80.0\n",
      "step-1980 summary: loss= 0.26082783937454224, training accuracy = 92.0\n",
      "step-2010 summary: loss= 0.270230233669281, training accuracy = 90.0\n",
      "step-2040 summary: loss= 0.535529613494873, training accuracy = 86.0\n",
      "step-2070 summary: loss= 0.37225914001464844, training accuracy = 88.0\n",
      "step-2100 summary: loss= 0.2568666934967041, training accuracy = 94.0\n",
      "step-2130 summary: loss= 0.25505930185317993, training accuracy = 92.0\n",
      "step-2160 summary: loss= 0.24475312232971191, training accuracy = 92.0\n",
      "step-2190 summary: loss= 0.4376705586910248, training accuracy = 90.0\n",
      "step-2220 summary: loss= 0.21437789499759674, training accuracy = 96.0\n",
      "step-2250 summary: loss= 0.16921386122703552, training accuracy = 96.0\n",
      "step-2280 summary: loss= 0.2650347352027893, training accuracy = 94.0\n",
      "step-2310 summary: loss= 0.24117541313171387, training accuracy = 94.0\n",
      "step-2340 summary: loss= 0.17614386975765228, training accuracy = 94.0\n",
      "step-2370 summary: loss= 0.34661391377449036, training accuracy = 90.0\n",
      "step-2400 summary: loss= 0.1855308711528778, training accuracy = 94.0\n",
      "step-2430 summary: loss= 0.2714967727661133, training accuracy = 92.0\n",
      "step-2460 summary: loss= 0.33130863308906555, training accuracy = 88.0\n",
      "step-2490 summary: loss= 0.22817136347293854, training accuracy = 92.0\n",
      "step-2520 summary: loss= 0.34724023938179016, training accuracy = 92.0\n",
      "step-2550 summary: loss= 0.23344403505325317, training accuracy = 94.0\n",
      "step-2580 summary: loss= 0.20944902300834656, training accuracy = 92.0\n",
      "step-2610 summary: loss= 0.19284939765930176, training accuracy = 96.0\n",
      "step-2640 summary: loss= 0.2113361954689026, training accuracy = 90.0\n",
      "step-2670 summary: loss= 0.23550429940223694, training accuracy = 92.0\n",
      "step-2700 summary: loss= 0.13367097079753876, training accuracy = 96.0\n",
      "step-2730 summary: loss= 0.12845540046691895, training accuracy = 98.0\n",
      "step-2760 summary: loss= 0.38283541798591614, training accuracy = 90.0\n",
      "step-2790 summary: loss= 0.3097410798072815, training accuracy = 94.0\n",
      "step-2820 summary: loss= 0.2485998421907425, training accuracy = 94.0\n",
      "step-2850 summary: loss= 0.3788332939147949, training accuracy = 88.0\n",
      "step-2880 summary: loss= 0.41857248544692993, training accuracy = 86.0\n",
      "step-2910 summary: loss= 0.1858057975769043, training accuracy = 94.0\n",
      "step-2940 summary: loss= 0.1624961644411087, training accuracy = 96.0\n",
      "step-2970 summary: loss= 0.09892896562814713, training accuracy = 100.0\n",
      "step-3000 summary: loss= 0.1747226119041443, training accuracy = 92.0\n",
      "step-3030 summary: loss= 0.36204519867897034, training accuracy = 90.0\n",
      "step-3060 summary: loss= 0.2916240990161896, training accuracy = 88.0\n",
      "step-3090 summary: loss= 0.2679908275604248, training accuracy = 92.0\n",
      "step-3120 summary: loss= 0.1348838061094284, training accuracy = 98.0\n",
      "step-3150 summary: loss= 0.10701555013656616, training accuracy = 96.0\n",
      "step-3180 summary: loss= 0.12670862674713135, training accuracy = 96.0\n",
      "step-3210 summary: loss= 0.21690185368061066, training accuracy = 92.0\n",
      "step-3240 summary: loss= 0.28124314546585083, training accuracy = 90.0\n",
      "step-3270 summary: loss= 0.29772552847862244, training accuracy = 92.0\n",
      "step-3300 summary: loss= 0.09246275573968887, training accuracy = 98.0\n",
      "step-3330 summary: loss= 0.1605745106935501, training accuracy = 94.0\n",
      "step-3360 summary: loss= 0.08879406750202179, training accuracy = 98.0\n",
      "step-3390 summary: loss= 0.19078044593334198, training accuracy = 94.0\n",
      "step-3420 summary: loss= 0.2307436317205429, training accuracy = 92.0\n",
      "step-3450 summary: loss= 0.14957645535469055, training accuracy = 96.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-3480 summary: loss= 0.12134347856044769, training accuracy = 96.0\n",
      "step-3510 summary: loss= 0.2362785041332245, training accuracy = 96.0\n",
      "step-3540 summary: loss= 0.3389419913291931, training accuracy = 94.0\n",
      "step-3570 summary: loss= 0.2015899270772934, training accuracy = 94.0\n",
      "step-3600 summary: loss= 0.36558687686920166, training accuracy = 88.0\n",
      "step-3630 summary: loss= 0.14772148430347443, training accuracy = 96.0\n",
      "step-3660 summary: loss= 0.2773134112358093, training accuracy = 92.0\n",
      "step-3690 summary: loss= 0.28440919518470764, training accuracy = 94.0\n",
      "step-3720 summary: loss= 0.4302772283554077, training accuracy = 86.0\n",
      "step-3750 summary: loss= 0.058181632310152054, training accuracy = 98.0\n",
      "step-3780 summary: loss= 0.1276324838399887, training accuracy = 96.0\n",
      "step-3810 summary: loss= 0.18975797295570374, training accuracy = 94.0\n",
      "step-3840 summary: loss= 0.06524603068828583, training accuracy = 98.0\n",
      "step-3870 summary: loss= 0.2021210640668869, training accuracy = 94.0\n",
      "step-3900 summary: loss= 0.1089368611574173, training accuracy = 100.0\n",
      "step-3930 summary: loss= 0.1791643649339676, training accuracy = 94.0\n",
      "step-3960 summary: loss= 0.22123533487319946, training accuracy = 94.0\n",
      "step-3990 summary: loss= 0.18985936045646667, training accuracy = 92.0\n",
      "step-4020 summary: loss= 0.12900026142597198, training accuracy = 94.0\n",
      "step-4050 summary: loss= 0.10843584686517715, training accuracy = 96.0\n",
      "step-4080 summary: loss= 0.09049100428819656, training accuracy = 96.0\n",
      "step-4110 summary: loss= 0.09668136388063431, training accuracy = 98.0\n",
      "step-4140 summary: loss= 0.10407710820436478, training accuracy = 96.0\n",
      "step-4170 summary: loss= 0.18875087797641754, training accuracy = 98.0\n",
      "step-4200 summary: loss= 0.10750763863325119, training accuracy = 96.0\n",
      "step-4230 summary: loss= 0.2290210723876953, training accuracy = 92.0\n",
      "step-4260 summary: loss= 0.060409169644117355, training accuracy = 100.0\n",
      "step-4290 summary: loss= 0.17540021240711212, training accuracy = 94.0\n",
      "step-4320 summary: loss= 0.10143322497606277, training accuracy = 96.0\n",
      "step-4350 summary: loss= 0.15917259454727173, training accuracy = 96.0\n",
      "step-4380 summary: loss= 0.17101354897022247, training accuracy = 98.0\n",
      "step-4410 summary: loss= 0.04044952616095543, training accuracy = 100.0\n",
      "step-4440 summary: loss= 0.1641422063112259, training accuracy = 92.0\n",
      "step-4470 summary: loss= 0.07315755635499954, training accuracy = 98.0\n",
      "step-4500 summary: loss= 0.44954442977905273, training accuracy = 86.0\n",
      "step-4530 summary: loss= 0.12402423471212387, training accuracy = 98.0\n",
      "step-4560 summary: loss= 0.15760383009910583, training accuracy = 94.0\n",
      "step-4590 summary: loss= 0.028368178755044937, training accuracy = 100.0\n",
      "step-4620 summary: loss= 0.10847466439008713, training accuracy = 94.0\n",
      "step-4650 summary: loss= 0.05705621466040611, training accuracy = 98.0\n",
      "step-4680 summary: loss= 0.08645506948232651, training accuracy = 98.0\n",
      "step-4710 summary: loss= 0.04323427751660347, training accuracy = 98.0\n",
      "step-4740 summary: loss= 0.04460340738296509, training accuracy = 100.0\n",
      "step-4770 summary: loss= 0.07642719894647598, training accuracy = 100.0\n",
      "step-4800 summary: loss= 0.1016247346997261, training accuracy = 98.0\n",
      "step-4830 summary: loss= 0.13547733426094055, training accuracy = 92.0\n",
      "step-4860 summary: loss= 0.16516420245170593, training accuracy = 98.0\n",
      "step-4890 summary: loss= 0.08717132359743118, training accuracy = 98.0\n",
      "step-4920 summary: loss= 0.13964839279651642, training accuracy = 98.0\n",
      "step-4950 summary: loss= 0.2618153989315033, training accuracy = 94.0\n",
      "step-4980 summary: loss= 0.028167514130473137, training accuracy = 100.0\n",
      "step-5010 summary: loss= 0.1005069687962532, training accuracy = 96.0\n",
      "step-5040 summary: loss= 0.07542969286441803, training accuracy = 96.0\n",
      "step-5070 summary: loss= 0.34836557507514954, training accuracy = 94.0\n",
      "step-5100 summary: loss= 0.19015216827392578, training accuracy = 96.0\n",
      "step-5130 summary: loss= 0.1137114018201828, training accuracy = 94.0\n",
      "step-5160 summary: loss= 0.05469237267971039, training accuracy = 100.0\n",
      "step-5190 summary: loss= 0.1096653938293457, training accuracy = 98.0\n",
      "step-5220 summary: loss= 0.08825108408927917, training accuracy = 96.0\n",
      "step-5250 summary: loss= 0.1482292264699936, training accuracy = 96.0\n",
      "step-5280 summary: loss= 0.10137895494699478, training accuracy = 98.0\n",
      "step-5310 summary: loss= 0.11432457715272903, training accuracy = 98.0\n",
      "step-5340 summary: loss= 0.02961561642587185, training accuracy = 98.0\n",
      "step-5370 summary: loss= 0.051141127943992615, training accuracy = 100.0\n",
      "step-5400 summary: loss= 0.07737301290035248, training accuracy = 100.0\n",
      "step-5430 summary: loss= 0.06679844111204147, training accuracy = 98.0\n",
      "step-5460 summary: loss= 0.2558403015136719, training accuracy = 94.0\n",
      "step-5490 summary: loss= 0.049359068274497986, training accuracy = 100.0\n",
      "step-5520 summary: loss= 0.1674090027809143, training accuracy = 96.0\n",
      "step-5550 summary: loss= 0.12798239290714264, training accuracy = 96.0\n",
      "step-5580 summary: loss= 0.05375812575221062, training accuracy = 100.0\n",
      "step-5610 summary: loss= 0.08264430612325668, training accuracy = 96.0\n",
      "step-5640 summary: loss= 0.057469695806503296, training accuracy = 100.0\n",
      "step-5670 summary: loss= 0.0361490361392498, training accuracy = 100.0\n",
      "step-5700 summary: loss= 0.11016944795846939, training accuracy = 96.0\n",
      "step-5730 summary: loss= 0.16443167626857758, training accuracy = 94.0\n",
      "step-5760 summary: loss= 0.1432676762342453, training accuracy = 96.0\n",
      "step-5790 summary: loss= 0.027865463867783546, training accuracy = 100.0\n",
      "step-5820 summary: loss= 0.07311716675758362, training accuracy = 98.0\n",
      "step-5850 summary: loss= 0.044609859585762024, training accuracy = 98.0\n",
      "step-5880 summary: loss= 0.08007346093654633, training accuracy = 96.0\n",
      "step-5910 summary: loss= 0.12313853204250336, training accuracy = 94.0\n",
      "step-5940 summary: loss= 0.1380627453327179, training accuracy = 98.0\n",
      "step-5970 summary: loss= 0.0732819139957428, training accuracy = 98.0\n",
      "step-6000 summary: loss= 0.158479243516922, training accuracy = 96.0\n",
      "step-6030 summary: loss= 0.06883065402507782, training accuracy = 98.0\n",
      "step-6060 summary: loss= 0.07499966025352478, training accuracy = 98.0\n",
      "step-6090 summary: loss= 0.23226357996463776, training accuracy = 96.0\n",
      "step-6120 summary: loss= 0.24363259971141815, training accuracy = 94.0\n",
      "step-6150 summary: loss= 0.133517324924469, training accuracy = 98.0\n",
      "step-6180 summary: loss= 0.09116104990243912, training accuracy = 96.0\n",
      "step-6210 summary: loss= 0.22244025766849518, training accuracy = 92.0\n",
      "step-6240 summary: loss= 0.06307824701070786, training accuracy = 98.0\n",
      "step-6270 summary: loss= 0.036344900727272034, training accuracy = 100.0\n",
      "step-6300 summary: loss= 0.04900369048118591, training accuracy = 100.0\n",
      "step-6330 summary: loss= 0.10965564846992493, training accuracy = 96.0\n",
      "step-6360 summary: loss= 0.05787021666765213, training accuracy = 96.0\n",
      "step-6390 summary: loss= 0.2740200161933899, training accuracy = 94.0\n",
      "step-6420 summary: loss= 0.04504629969596863, training accuracy = 98.0\n",
      "step-6450 summary: loss= 0.12382948398590088, training accuracy = 98.0\n",
      "step-6480 summary: loss= 0.12645071744918823, training accuracy = 96.0\n",
      "step-6510 summary: loss= 0.11134270578622818, training accuracy = 94.0\n",
      "step-6540 summary: loss= 0.19298887252807617, training accuracy = 96.0\n",
      "step-6570 summary: loss= 0.0941319614648819, training accuracy = 100.0\n",
      "step-6600 summary: loss= 0.049574486911296844, training accuracy = 98.0\n",
      "step-6630 summary: loss= 0.033049020916223526, training accuracy = 100.0\n",
      "step-6660 summary: loss= 0.10118246078491211, training accuracy = 98.0\n",
      "step-6690 summary: loss= 0.024539444595575333, training accuracy = 100.0\n",
      "step-6720 summary: loss= 0.03647251054644585, training accuracy = 100.0\n",
      "step-6750 summary: loss= 0.12733127176761627, training accuracy = 96.0\n",
      "step-6780 summary: loss= 0.0475815087556839, training accuracy = 98.0\n",
      "step-6810 summary: loss= 0.08208280056715012, training accuracy = 98.0\n",
      "step-6840 summary: loss= 0.06450702250003815, training accuracy = 100.0\n",
      "step-6870 summary: loss= 0.054586589336395264, training accuracy = 98.0\n",
      "step-6900 summary: loss= 0.09621705859899521, training accuracy = 98.0\n",
      "step-6930 summary: loss= 0.1831461489200592, training accuracy = 96.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-6960 summary: loss= 0.08386380970478058, training accuracy = 98.0\n",
      "step-6990 summary: loss= 0.15002961456775665, training accuracy = 94.0\n",
      "step-7020 summary: loss= 0.02352764643728733, training accuracy = 100.0\n",
      "step-7050 summary: loss= 0.11945530772209167, training accuracy = 98.0\n",
      "step-7080 summary: loss= 0.07296118140220642, training accuracy = 98.0\n",
      "step-7110 summary: loss= 0.1096644476056099, training accuracy = 96.0\n",
      "step-7140 summary: loss= 0.13682757318019867, training accuracy = 96.0\n",
      "step-7170 summary: loss= 0.08283397555351257, training accuracy = 98.0\n",
      "step-7200 summary: loss= 0.06675701588392258, training accuracy = 100.0\n",
      "step-7230 summary: loss= 0.1974511444568634, training accuracy = 92.0\n",
      "step-7260 summary: loss= 0.10661714524030685, training accuracy = 98.0\n",
      "step-7290 summary: loss= 0.21069782972335815, training accuracy = 96.0\n",
      "step-7320 summary: loss= 0.04482416436076164, training accuracy = 100.0\n",
      "step-7350 summary: loss= 0.03279641270637512, training accuracy = 100.0\n",
      "step-7380 summary: loss= 0.022132081910967827, training accuracy = 100.0\n",
      "step-7410 summary: loss= 0.09420114010572433, training accuracy = 96.0\n",
      "step-7440 summary: loss= 0.05960424244403839, training accuracy = 98.0\n",
      "step-7470 summary: loss= 0.02437100186944008, training accuracy = 100.0\n",
      "step-7500 summary: loss= 0.04189801216125488, training accuracy = 100.0\n",
      "step-7530 summary: loss= 0.09545671194791794, training accuracy = 98.0\n",
      "step-7560 summary: loss= 0.0511304996907711, training accuracy = 100.0\n",
      "step-7590 summary: loss= 0.016180898994207382, training accuracy = 100.0\n",
      "step-7620 summary: loss= 0.1301337480545044, training accuracy = 96.0\n",
      "step-7650 summary: loss= 0.3892951011657715, training accuracy = 90.0\n",
      "step-7680 summary: loss= 0.11025719344615936, training accuracy = 98.0\n",
      "step-7710 summary: loss= 0.04265579581260681, training accuracy = 98.0\n",
      "step-7740 summary: loss= 0.12132615596055984, training accuracy = 92.0\n",
      "step-7770 summary: loss= 0.12150906026363373, training accuracy = 98.0\n",
      "step-7800 summary: loss= 0.044526491314172745, training accuracy = 98.0\n",
      "step-7830 summary: loss= 0.06088703125715256, training accuracy = 98.0\n",
      "step-7860 summary: loss= 0.0530022569000721, training accuracy = 98.0\n",
      "step-7890 summary: loss= 0.027829419821500778, training accuracy = 98.0\n",
      "step-7920 summary: loss= 0.03687794506549835, training accuracy = 100.0\n",
      "step-7950 summary: loss= 0.09321973472833633, training accuracy = 96.0\n",
      "step-7980 summary: loss= 0.023904314264655113, training accuracy = 100.0\n",
      "step-8010 summary: loss= 0.03235093876719475, training accuracy = 100.0\n",
      "step-8040 summary: loss= 0.0883340984582901, training accuracy = 96.0\n",
      "step-8070 summary: loss= 0.03662195801734924, training accuracy = 100.0\n",
      "step-8100 summary: loss= 0.09405170381069183, training accuracy = 94.0\n",
      "step-8130 summary: loss= 0.06033753603696823, training accuracy = 100.0\n",
      "step-8160 summary: loss= 0.020098000764846802, training accuracy = 100.0\n",
      "step-8190 summary: loss= 0.1677291989326477, training accuracy = 96.0\n",
      "step-8220 summary: loss= 0.13835325837135315, training accuracy = 98.0\n",
      "step-8250 summary: loss= 0.032602712512016296, training accuracy = 100.0\n",
      "step-8280 summary: loss= 0.0891309455037117, training accuracy = 96.0\n",
      "step-8310 summary: loss= 0.03795945271849632, training accuracy = 98.0\n",
      "step-8340 summary: loss= 0.05571999028325081, training accuracy = 100.0\n",
      "step-8370 summary: loss= 0.03607122600078583, training accuracy = 98.0\n",
      "step-8400 summary: loss= 0.05636518821120262, training accuracy = 98.0\n",
      "step-8430 summary: loss= 0.11685293167829514, training accuracy = 94.0\n",
      "step-8460 summary: loss= 0.26414358615875244, training accuracy = 96.0\n",
      "step-8490 summary: loss= 0.03841321915388107, training accuracy = 100.0\n",
      "step-8520 summary: loss= 0.041793640702962875, training accuracy = 98.0\n",
      "step-8550 summary: loss= 0.052192918956279755, training accuracy = 98.0\n",
      "step-8580 summary: loss= 0.014284350909292698, training accuracy = 100.0\n",
      "step-8610 summary: loss= 0.07330146431922913, training accuracy = 98.0\n",
      "step-8640 summary: loss= 0.06923644989728928, training accuracy = 98.0\n",
      "step-8670 summary: loss= 0.06535648554563522, training accuracy = 98.0\n",
      "step-8700 summary: loss= 0.007905093021690845, training accuracy = 100.0\n",
      "step-8730 summary: loss= 0.035162270069122314, training accuracy = 100.0\n",
      "step-8760 summary: loss= 0.016748733818531036, training accuracy = 100.0\n",
      "step-8790 summary: loss= 0.04944504052400589, training accuracy = 100.0\n",
      "step-8820 summary: loss= 0.055774059146642685, training accuracy = 98.0\n",
      "step-8850 summary: loss= 0.2165563851594925, training accuracy = 94.0\n",
      "step-8880 summary: loss= 0.10680833458900452, training accuracy = 94.0\n",
      "step-8910 summary: loss= 0.047207508236169815, training accuracy = 98.0\n",
      "step-8940 summary: loss= 0.043056420981884, training accuracy = 98.0\n",
      "step-8970 summary: loss= 0.03688744828104973, training accuracy = 100.0\n",
      "step-9000 summary: loss= 0.026378650218248367, training accuracy = 100.0\n",
      "step-9030 summary: loss= 0.035770539194345474, training accuracy = 100.0\n",
      "step-9060 summary: loss= 0.1861584484577179, training accuracy = 96.0\n",
      "step-9090 summary: loss= 0.0853709802031517, training accuracy = 96.0\n",
      "step-9120 summary: loss= 0.07380718737840652, training accuracy = 98.0\n",
      "step-9150 summary: loss= 0.022387200966477394, training accuracy = 100.0\n",
      "step-9180 summary: loss= 0.03785126656293869, training accuracy = 100.0\n",
      "step-9210 summary: loss= 0.016311751678586006, training accuracy = 100.0\n",
      "step-9240 summary: loss= 0.10714415460824966, training accuracy = 96.0\n",
      "step-9270 summary: loss= 0.0505850687623024, training accuracy = 98.0\n",
      "step-9300 summary: loss= 0.11365284770727158, training accuracy = 94.0\n",
      "step-9330 summary: loss= 0.04371945187449455, training accuracy = 98.0\n",
      "step-9360 summary: loss= 0.07317418605089188, training accuracy = 98.0\n",
      "step-9390 summary: loss= 0.10724850744009018, training accuracy = 98.0\n",
      "step-9420 summary: loss= 0.02669256180524826, training accuracy = 100.0\n",
      "step-9450 summary: loss= 0.05992540717124939, training accuracy = 98.0\n",
      "step-9480 summary: loss= 0.09684743732213974, training accuracy = 94.0\n",
      "step-9510 summary: loss= 0.032375216484069824, training accuracy = 98.0\n",
      "step-9540 summary: loss= 0.04732094332575798, training accuracy = 98.0\n",
      "step-9570 summary: loss= 0.09020179510116577, training accuracy = 96.0\n",
      "step-9600 summary: loss= 0.016776861622929573, training accuracy = 100.0\n",
      "step-9630 summary: loss= 0.05898535996675491, training accuracy = 98.0\n",
      "step-9660 summary: loss= 0.07202458381652832, training accuracy = 98.0\n",
      "step-9690 summary: loss= 0.06371676176786423, training accuracy = 98.0\n",
      "step-9720 summary: loss= 0.07358130067586899, training accuracy = 96.0\n",
      "step-9750 summary: loss= 0.04151986911892891, training accuracy = 98.0\n",
      "step-9780 summary: loss= 0.03303281590342522, training accuracy = 100.0\n",
      "step-9810 summary: loss= 0.07826030254364014, training accuracy = 98.0\n",
      "step-9840 summary: loss= 0.019412534311413765, training accuracy = 100.0\n",
      "step-9870 summary: loss= 0.05457101762294769, training accuracy = 98.0\n",
      "step-9900 summary: loss= 0.03531039506196976, training accuracy = 98.0\n",
      "step-9930 summary: loss= 0.14081066846847534, training accuracy = 96.0\n",
      "step-9960 summary: loss= 0.043777089565992355, training accuracy = 98.0\n",
      "step-9990 summary: loss= 0.179402157664299, training accuracy = 96.0\n",
      "step-10020 summary: loss= 0.049715571105480194, training accuracy = 96.0\n",
      "step-10050 summary: loss= 0.027055911719799042, training accuracy = 100.0\n",
      "step-10080 summary: loss= 0.015508758835494518, training accuracy = 100.0\n",
      "step-10110 summary: loss= 0.027349965646862984, training accuracy = 100.0\n",
      "step-10140 summary: loss= 0.071573905646801, training accuracy = 100.0\n",
      "step-10170 summary: loss= 0.09676764905452728, training accuracy = 96.0\n",
      "step-10200 summary: loss= 0.06915280967950821, training accuracy = 98.0\n",
      "step-10230 summary: loss= 0.07017788290977478, training accuracy = 98.0\n",
      "step-10260 summary: loss= 0.04285544902086258, training accuracy = 98.0\n",
      "step-10290 summary: loss= 0.11912775039672852, training accuracy = 96.0\n",
      "step-10320 summary: loss= 0.06360968202352524, training accuracy = 96.0\n",
      "step-10350 summary: loss= 0.03395644947886467, training accuracy = 98.0\n",
      "step-10380 summary: loss= 0.027482278645038605, training accuracy = 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-10410 summary: loss= 0.029098834842443466, training accuracy = 100.0\n",
      "step-10440 summary: loss= 0.10205631703138351, training accuracy = 98.0\n",
      "step-10470 summary: loss= 0.29733186960220337, training accuracy = 88.0\n",
      "step-10500 summary: loss= 0.050845712423324585, training accuracy = 98.0\n",
      "step-10530 summary: loss= 0.11945413053035736, training accuracy = 98.0\n",
      "step-10560 summary: loss= 0.028179556131362915, training accuracy = 98.0\n",
      "step-10590 summary: loss= 0.02153601683676243, training accuracy = 100.0\n",
      "step-10620 summary: loss= 0.05272936075925827, training accuracy = 96.0\n",
      "step-10650 summary: loss= 0.048596058040857315, training accuracy = 98.0\n",
      "step-10680 summary: loss= 0.04887491092085838, training accuracy = 98.0\n",
      "step-10710 summary: loss= 0.01130053959786892, training accuracy = 100.0\n",
      "step-10740 summary: loss= 0.013478875160217285, training accuracy = 100.0\n",
      "step-10770 summary: loss= 0.03929968178272247, training accuracy = 98.0\n",
      "step-10800 summary: loss= 0.01786111295223236, training accuracy = 100.0\n",
      "step-10830 summary: loss= 0.017593801021575928, training accuracy = 100.0\n",
      "step-10860 summary: loss= 0.02322511188685894, training accuracy = 100.0\n",
      "step-10890 summary: loss= 0.026216216385364532, training accuracy = 100.0\n",
      "step-10920 summary: loss= 0.015897728502750397, training accuracy = 100.0\n",
      "step-10950 summary: loss= 0.08213190734386444, training accuracy = 98.0\n",
      "step-10980 summary: loss= 0.00920861680060625, training accuracy = 100.0\n",
      "step-11010 summary: loss= 0.034096963703632355, training accuracy = 98.0\n",
      "step-11040 summary: loss= 0.027500370517373085, training accuracy = 100.0\n",
      "step-11070 summary: loss= 0.12435760349035263, training accuracy = 98.0\n",
      "step-11100 summary: loss= 0.10539725422859192, training accuracy = 96.0\n",
      "step-11130 summary: loss= 0.055069513618946075, training accuracy = 98.0\n",
      "step-11160 summary: loss= 0.07669488340616226, training accuracy = 96.0\n",
      "step-11190 summary: loss= 0.05230619013309479, training accuracy = 100.0\n",
      "step-11220 summary: loss= 0.012479543685913086, training accuracy = 100.0\n",
      "step-11250 summary: loss= 0.02804250456392765, training accuracy = 100.0\n",
      "step-11280 summary: loss= 0.02450587786734104, training accuracy = 100.0\n",
      "step-11310 summary: loss= 0.04036163166165352, training accuracy = 98.0\n",
      "step-11340 summary: loss= 0.011052695102989674, training accuracy = 100.0\n",
      "step-11370 summary: loss= 0.16776864230632782, training accuracy = 96.0\n",
      "step-11400 summary: loss= 0.07833081483840942, training accuracy = 98.0\n",
      "step-11430 summary: loss= 0.007268046028912067, training accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "n_itrs = 7\n",
    "model = MatrixCapsule()\n",
    "print(\"session started\")\n",
    "\n",
    "n_itrs = 20000\n",
    "for step in range(n_itrs):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    batch_xs = batch_xs.reshape(batch_size, 28, 28,1)\n",
    "    batch_ys = batch_ys.reshape(batch_size, 10)\n",
    "    loss, acc =  model.train(batch_xs,batch_ys)\n",
    "    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
    "    #print(step)\n",
    "    if (step % 30 == 0):\n",
    "        print(\"step-{} summary: loss= {}, training accuracy = {}\".format(step, loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jai GuruDev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
