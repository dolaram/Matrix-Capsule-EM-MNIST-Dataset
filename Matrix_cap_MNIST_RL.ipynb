{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cn1lab005/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "# from config import cfg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_routing = 2\n",
    "ac_lambda0 = 0.01, \n",
    "#'\\lambda in the activation function a_c, iteration 0')\n",
    "ac_lambda_step = 0.01,\n",
    "#'It is described that \\lambda increases at each iteration with a fixed schedule, however specific super parameters is absent.')\n",
    "epsilon = 1e-9\n",
    "\n",
    "#batch_size = 50\n",
    "################################\n",
    "A = 32 # , 'number of channels in output from ReLU Conv1')\n",
    "B = 8 # , 'number of capsules in output from PrimaryCaps')\n",
    "C = 16 #, 'number of channels in output from ConvCaps1')\n",
    "D = 16 # , 'number of channels in output from ConvCaps2')\n",
    "is_train = True\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_tile(input, kernel, stride):\n",
    "    # output = tf.extract_image_patches(input, ksizes=[1, kernel, kernel, 1], strides=[1, stride, stride, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    input_shape = input.get_shape()\n",
    "    tile_filter = np.zeros(shape=[kernel, kernel, input_shape[3],\n",
    "                                  kernel * kernel], dtype=np.float32)\n",
    "    for i in range(kernel):\n",
    "        for j in range(kernel):\n",
    "            tile_filter[i, j, :, i * kernel + j] = 1.0\n",
    "\n",
    "    tile_filter_op = tf.constant(tile_filter, dtype=tf.float32)\n",
    "    output = tf.nn.depthwise_conv2d(input, tile_filter_op, strides=[\n",
    "                                    1, stride, stride, 1], padding='VALID')\n",
    "    output_shape = output.get_shape()\n",
    "    output = tf.reshape(output, shape=[-1, int( # -1== int(output_shape[0])\n",
    "        output_shape[1]), int(output_shape[2]), int(input_shape[3]), kernel * kernel])\n",
    "    print(output.get_shape(),\"fdsggs\")\n",
    "    output = tf.transpose(output, perm=[0, 1, 2, 4, 3])\n",
    "\n",
    "    return output\n",
    "\n",
    "# input should be a tensor with size as [batch_size, caps_num_i, 16]\n",
    "def mat_transform(input, caps_num_c, regularizer, bs):\n",
    "    #batch_size = input.get_shape()[0]\n",
    "    caps_num_i = int(input.get_shape()[1])\n",
    "    output = tf.reshape(input, shape=[-1, caps_num_i, 1, 4, 4])# batch_size = -1\n",
    "    # the output of capsule is miu, the mean of a Gaussian, and activation, the sum of probabilities\n",
    "    # it has no relationship with the absolute values of w and votes\n",
    "    # using weights with bigger stddev helps numerical stability\n",
    "    w = slim.variable('w', shape=[1, caps_num_i, caps_num_c, 4, 4], dtype=tf.float32,\n",
    "                      initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1.0),\n",
    "                      regularizer=regularizer)\n",
    "    print(\"w\",w.get_shape())\n",
    "    with tf.variable_scope('tile___1'):\n",
    "        w = tf.tile(w, [bs, 1, 1, 1, 1])\n",
    "    print(\"w\",w.get_shape())\n",
    "    with tf.variable_scope('tile___2'):\n",
    "        output = tf.tile(output, [1, 1, caps_num_c, 1, 1])\n",
    "    with tf.variable_scope('tile___3'):\n",
    "        k = tf.matmul(output, w)\n",
    "        votes = tf.reshape(k, [-1, caps_num_i, caps_num_c, 16]) #batch_size = -1\n",
    "    #votes = tf.reshape(tf.matmul(output, w), [batch_size, caps_num_i, caps_num_c, 16])\n",
    "\n",
    "    return votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_routing(votes, activation, caps_num_c, regularizer, r_in):\n",
    "    test = []\n",
    "\n",
    "    #batch_size = votes.get_shape()[0]\n",
    "    caps_num_i = int(activation.get_shape()[1])\n",
    "    n_channels = int(votes.get_shape()[-1])\n",
    "\n",
    "    sigma_square = []\n",
    "    miu = []\n",
    "    activation_out = []\n",
    "    beta_v = slim.variable('beta_v', shape=[caps_num_c, n_channels], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0),#tf.truncated_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                           regularizer=regularizer)\n",
    "    beta_a = slim.variable('beta_a', shape=[caps_num_c], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0),#tf.truncated_normal_initializer(mean=0.0, stddev=0.01),\n",
    "                           regularizer=regularizer)\n",
    "\n",
    "    # votes_in = tf.stop_gradient(votes, name='stop_gradient_votes')\n",
    "    # activation_in = tf.stop_gradient(activation, name='stop_gradient_activation')\n",
    "    votes_in = votes\n",
    "    print(votes_in,' = votes')\n",
    "    activation_in = activation\n",
    "\n",
    "    for iters in range(iter_routing):\n",
    "        # if iters == cfg.iter_routing-1:\n",
    "\n",
    "        # e-step\n",
    "        if iters == 0:\n",
    "            r = r_in# tf.constant(np.ones([batch_size, caps_num_i, caps_num_c], dtype=np.float32) / caps_num_c)\n",
    "            print(r.get_shape(),\"r shape__________\")\n",
    "        else:\n",
    "            # Contributor: Yunzhi Shi\n",
    "            # log and exp here provide higher numerical stability especially for bigger number of iterations\n",
    "            log_p_c_h = -tf.log(tf.sqrt(sigma_square)) - \\\n",
    "                        (tf.square(votes_in - miu) / (2 * sigma_square))\n",
    "            log_p_c_h = log_p_c_h - \\\n",
    "                        (tf.reduce_max(log_p_c_h, axis=[2, 3], keep_dims=True) - tf.log(10.0))\n",
    "            p_c = tf.exp(tf.reduce_sum(log_p_c_h, axis=3))\n",
    "\n",
    "            ap = p_c * tf.reshape(activation_out, shape=[-1, 1, caps_num_c]) # batch_size\n",
    "            print(ap.get_shape(),\"ap\")\n",
    "            # ap = tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            r = ap / (tf.reduce_sum(ap, axis=2, keepdims=True) + epsilon)\n",
    "\n",
    "        # m-step\n",
    "        r = r * activation_in\n",
    "        r = r / (tf.reduce_sum(r, axis=2, keepdims=True)+epsilon)\n",
    "\n",
    "        r_sum = tf.reduce_sum(r, axis=1, keepdims=True)\n",
    "        r1 = tf.reshape(r / (r_sum + epsilon),\n",
    "                        shape=[-1 , caps_num_i, caps_num_c, 1]) # batch_size\n",
    "        print(r1.get_shape(),\"r1\")\n",
    "        miu = tf.reduce_sum(votes_in * r1, axis=1, keepdims=True)\n",
    "        sigma_square = tf.reduce_sum(tf.square(votes_in - miu) * r1,\n",
    "                                     axis=1, keepdims=True) + epsilon\n",
    "\n",
    "        if iters == iter_routing-1:\n",
    "            r_sum = tf.reshape(r_sum, [-1, caps_num_c, 1])  # batch_size\n",
    "            print(r_sum.get_shape(),\"r_sum\")\n",
    "            cost_h = (beta_v + tf.log(tf.sqrt(tf.reshape(sigma_square,\n",
    "                                                         shape=[-1, caps_num_c, n_channels])))) * r_sum\n",
    "            print(cost_h.get_shape(),\"cost_h\") # batch_size\n",
    "            activation_out = tf.nn.softmax(ac_lambda0 * (beta_a - tf.reduce_sum(cost_h, axis=2)))\n",
    "        else:\n",
    "            activation_out = tf.nn.softmax(r_sum)\n",
    "        # if iters <= cfg.iter_routing-1:\n",
    "        #     activation_out = tf.stop_gradient(activation_out, name='stop_gradient_activation')\n",
    "\n",
    "    return miu, activation_out, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_add(dataset_name: str):\n",
    "    import numpy as np\n",
    "    # TODO: get coord add for cifar10/100 datasets (32x32x3)\n",
    "    options = {'mnist': ([[[8., 8.], [12., 8.], [16., 8.]],\n",
    "                          [[8., 12.], [12., 12.], [16., 12.]],\n",
    "                          [[8., 16.], [12., 16.], [16., 16.]]], 28.),\n",
    "               'smallNORB': ([[[8., 8.], [12., 8.], [16., 8.], [24., 8.]],\n",
    "                              [[8., 12.], [12., 12.], [16., 12.], [24., 12.]],\n",
    "                              [[8., 16.], [12., 16.], [16., 16.], [24., 16.]],\n",
    "                              [[8., 24.], [12., 24.], [16., 24.], [24., 24.]]], 32.)\n",
    "               }\n",
    "    coord_add, scale = options[dataset_name]\n",
    "\n",
    "    coord_add = np.array(coord_add, dtype=np.float32) / scale\n",
    "\n",
    "    return coord_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for the Matrix Capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixCapsule(object):\n",
    "    def __init__(self, is_train=True):\n",
    "        tf.reset_default_graph()\n",
    "        self.graph = tf.Graph()\n",
    "        self._build_arch()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        print(\"Graph for Matrix Capsule is ready for training\")\n",
    "    def _build_arch(self):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name='X')\n",
    "        #X = tf.placeholder(tf.float32, shape=(50, 28, 28, 1))\n",
    "        self.Y = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        self.bs = tf.placeholder(tf.int32, shape=(), name='bs')\n",
    "        self.r_conv_caps1= tf.placeholder(tf.float32,[None, 72, C], name='r_conv_caps1') # 5*5*batch_size\n",
    "        #r_conv_caps1 = tf.placeholder(tf.float32,[5*5*batch_size, 72, C]) # 5*5*batch_size\n",
    "\n",
    "        self.r_conv_caps2 = tf.placeholder(tf.float32,[None, 144, D], name='r_conv_caps2') # 3*3*batch_size\n",
    "        #r_conv_caps2 = tf.placeholder(tf.float32,[3*3*batch_size, 144, D]) # 3*3*batch_size\n",
    "\n",
    "        self.r_class_caps = tf.placeholder(tf.float32,[None, 16, num_classes], name='r_class_caps') # 3*3*batch_size\n",
    "        #r_class_caps = tf.placeholder(tf.float32,[3*3*batch_size, 16, num_classes]) # 3*3*batch_size\n",
    "\n",
    "        self.coord_add_op_class_caps  = tf.placeholder(tf.float32,[None, 16, num_classes, 2], name='coord_add_op_class_caps')\n",
    "                                                                         # 3*3*batch_size\n",
    "        #coord_add_op_n  = tf.placeholder(tf.float32,[3*3*batch_size, 16, num_classes, 2]) # 3*3*batch_size\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        data_size = int(self.X.get_shape()[1])\n",
    "        # xavier initialization is necessary here to provide higher stability\n",
    "        initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n",
    "        # instead of initializing bias with constant 0, \n",
    "        # a truncated normal initializer is exploited here for higher stability \n",
    "        bias_initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)  # tf.constant_initializer(0.0)\n",
    "        # The paper didnot mention any regularization, a common l2 regularizer to weights is added here\n",
    "        weights_regularizer = tf.contrib.layers.l2_regularizer(5e-04)\n",
    "        # weights_initializer=initializer,\n",
    "        with slim.arg_scope([slim.conv2d], trainable=is_train, biases_initializer=bias_initializer, weights_regularizer=weights_regularizer):\n",
    "            with tf.variable_scope('relu_conv1'):\n",
    "                output = slim.conv2d(self.X, num_outputs=A, kernel_size=[5, 5], stride=2, padding='VALID', scope='relu_conv1', activation_fn=tf.nn.relu)\n",
    "                data_size = int(np.floor((data_size - 4) / 2))\n",
    "                #print(output.get_shape())\n",
    "                #print(data_size)\n",
    "                #assert output.get_shape() == [batch_size, data_size, data_size, 32]\n",
    "                votes__1 = output\n",
    "            with tf.variable_scope('primary_caps'):\n",
    "                pose = slim.conv2d(output, num_outputs=B * 16,kernel_size=[1, 1], stride=1, padding='VALID', scope='primary_caps', activation_fn=None)\n",
    "                activation = slim.conv2d(output, num_outputs=B, kernel_size=[\n",
    "                                         1, 1], stride=1, padding='VALID', scope='primary_caps/activation', activation_fn=tf.nn.sigmoid)\n",
    "                pose = tf.reshape(pose, shape=[-1, data_size, data_size, B, 16]) # (50, 12, 12, 8, 16)\n",
    "\n",
    "                print(pose.get_shape())\n",
    "                activation = tf.reshape(activation, shape=[-1, data_size, data_size, B, 1]) # (50, 12, 12, 8, 1)\n",
    "                print(activation.get_shape())\n",
    "                output = tf.concat([pose, activation], axis=4)\n",
    "                output = tf.reshape(output, shape=[-1, data_size, data_size, B * 17]) # (50, 12, 12, 136)\n",
    "                print(output.get_shape())\n",
    "\n",
    "                #assert output.get_shape() == [batch_size, data_size, data_size, B * 17]\n",
    "            with tf.variable_scope('conv_caps1') as scope:\n",
    "                output = kernel_tile(output, 3, 2)\n",
    "                data_size = int(np.floor((data_size - 2) / 2))\n",
    "                print(data_size) # 5 \n",
    "                output = tf.reshape(output, shape=[-1, 3 * 3 * B, 17]) \n",
    "                # batch_size * data_size * data_size  (1250, 72, 17) \n",
    "                print(\"1\",output.get_shape())\n",
    "                activation = tf.reshape(output[:, :, 16], shape=[-1, 3 * 3 * B, 1])\n",
    "                print(\"output shape ---------------\",output.get_shape())\n",
    "                print(\"activation shape----------------------\",activation.get_shape()) #  (1250, 72, 1)\n",
    "\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(output[:, :, :16], C, weights_regularizer,\n",
    "                                          bs = self.bs*data_size*data_size)\n",
    "                    #bs*data_size*data_size)\n",
    "\n",
    "                    print(votes.get_shape(),\"votes shape\")\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    caps_num_i = int(activation.get_shape()[1])\n",
    "\n",
    "                    miu, activation, _ = em_routing(votes, activation, C,\n",
    "                                                    weights_regularizer,self.r_conv_caps1)\n",
    "                    # miu, activation, _ = em_routing(votes, activation, C, weights_regularizer)\n",
    "                    print(\"activation\",activation.get_shape())\n",
    "                pose = tf.reshape(miu, shape=[-1, data_size, data_size, C, 16])\n",
    "                print(\"3\",pose.get_shape()) # 50, 5, 5, 16, 16)\n",
    "                activation = tf.reshape(activation, shape=[-1, data_size, data_size, C, 1])\n",
    "                print(\"activation\",activation.get_shape())\n",
    "                cat_size =  activation.get_shape()[3]*activation.get_shape()[4] + pose.get_shape()[3] *pose.get_shape()[4]\n",
    "                print(cat_size)\n",
    "                output = tf.reshape(tf.concat([pose, activation], axis=4),[-1, data_size, data_size, cat_size])\n",
    "                print(\"5\",output.get_shape()) # (50, 5, 5, 272)\n",
    "\n",
    "            with tf.variable_scope('conv_caps2') as scope:\n",
    "                output = kernel_tile(output, 3, 1)\n",
    "                data_size = int(np.floor((data_size - 2) / 1))\n",
    "                output = tf.reshape(output, shape=[-1, 3 * 3 * C, 17]) # batch_size * data_size * data_size\n",
    "                print(\"canv_caps2\",output.get_shape(), data_size)\n",
    "                activation = tf.reshape(output[:, :, 16], shape=[-1 , 3 * 3 * C, 1]) # batch_size * data_size * data_size\n",
    "                print(\"canv_caps2_activation\",activation.get_shape(), data_size)\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(output[:, :, :16], D, weights_regularizer,\n",
    "                                          bs = self.bs*data_size*data_size)\n",
    "                    print(votes.get_shape(),\"votes shape\")\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    caps_num_i = int(activation.get_shape()[1])\n",
    "                    print(caps_num_i,\"for 1\")\n",
    "                    miu, activation, _ = em_routing(votes, activation, D,\n",
    "                                                    weights_regularizer, self.r_conv_caps2)\n",
    "                pose = tf.reshape(miu, shape=[-1, D, 16]) # batch_size * data_size * data_size\n",
    "                print(\"4\",pose.get_shape())\n",
    "                activation = tf.reshape(activation, shape=[-1, D, 1]) # batch_size * data_size * data_size\n",
    "                print(\"4 ---activation\",activation.get_shape())\n",
    "            with tf.variable_scope('class_caps') as scope:\n",
    "                with tf.variable_scope('v') as scope:\n",
    "                    votes = mat_transform(pose, num_classes, weights_regularizer,\n",
    "                                          bs = self.bs*data_size*data_size)\n",
    "                    print(votes.get_shape(),\"votes.getshape\")\n",
    "                    assert votes.get_shape()[1:] == [D, num_classes, 16]\n",
    "                    '''coord_add = get_coord_add('mnist') \n",
    "                    coord_add = np.reshape(coord_add, newshape=[data_size * data_size, 1, 1, 2])\n",
    "                    coord_add = np.tile(coord_add, [bs, D, num_classes, 1])\n",
    "                    coord_add_op = tf.constant(coord_add, dtype=tf.float32)\n",
    "                    print(\"___coord_add______\",coord_add_op.shape)'''\n",
    "\n",
    "                    votes = tf.concat([self.coord_add_op_class_caps, votes], axis=3)\n",
    "                    print(votes.get_shape(),\"coorr vote shape after  jnbfv\")\n",
    "                with tf.variable_scope('routing') as scope:\n",
    "                    caps_num_i = int(activation.get_shape()[1])\n",
    "                    print(\"_____\",caps_num_i)\n",
    "                    miu, activation, test2 = em_routing(votes, activation, num_classes,\n",
    "                                                        weights_regularizer,self.r_class_caps)\n",
    "                output = tf.reshape(activation, shape=[-1, data_size, data_size, num_classes]) #batch_size\n",
    "                print(\"d op\",output.get_shape())\n",
    "            output = tf.reshape(tf.nn.avg_pool(output, ksize=[1, data_size, data_size, 1], strides=[\n",
    "                        1, 1, 1, 1], padding='VALID'), shape=[-1, num_classes]) # batch_size\n",
    "            print(\"miu  2\",miu.get_shape())\n",
    "            pose = tf.nn.avg_pool(tf.reshape(miu, shape=[-1, data_size, data_size,miu.get_shape()[2]*miu.get_shape()[3]\n",
    "                                        ]), ksize=[1, data_size, data_size, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "            print(\"output_size_posssss\",pose.get_shape())\n",
    "            #miu  2 (450, 1, 10, 18)\n",
    "            #output_size_posssss (50, 1, 1, 180)\n",
    "            pose_out = tf.reshape(pose, shape=[-1, num_classes, 18])\n",
    "            print(\"output_size\",pose_out.get_shape())\n",
    "            vector_j = tf.reshape(pose_out, shape= [-1, num_classes * 18])\n",
    "            \n",
    "        with tf.variable_scope('output_layer') as scope:\n",
    "            self.logits = tf.contrib.layers.fully_connected(vector_j, num_outputs=10, activation_fn=None)\n",
    "        print(\"shape of logits\",self.logits)\n",
    "        \n",
    "        with tf.variable_scope('loss') as scope:\n",
    "            self.cross_entropy_loss = tf.losses.softmax_cross_entropy(self.Y, self.logits)\n",
    "            #print(\"output_size\",self.logits.get_shape())\n",
    "\n",
    "        with tf.variable_scope('optimizer') as scope:\n",
    "            self.train_op = tf.train.AdamOptimizer(1e-3).minimize(self.cross_entropy_loss)\n",
    "\n",
    "        with tf.variable_scope('prediction') as scope:  \n",
    "            prediction = tf.nn.softmax(self.logits,-1)\n",
    "            self.y_hat = tf.to_int32(tf.argmax(prediction, axis=1))\n",
    "\n",
    "        with tf.variable_scope('acc'):\n",
    "            labels = tf.to_int32(tf.argmax(self.Y, axis=1))\n",
    "            correct_prediction = tf.equal(tf.to_int32(labels), self.y_hat)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n",
    "            \n",
    "    def train(self, batch_xs, batch_ys, batch_size_train):\n",
    "        coord_add = get_coord_add('mnist') \n",
    "        coord_add = np.reshape(coord_add, newshape=[3 * 3, 1, 1, 2]) #data_size =3\n",
    "        coord_add = np.tile(coord_add, [batch_size_train, D, num_classes, 1])\n",
    "        r_conv_caps1_in = np.ones([5*5*batch_size_train, 72, C]) / C\n",
    "        r_conv_caps2_in = np.ones([3*3*batch_size_train, 144, D]) / D\n",
    "        r_class_caps_in = np.ones([3*3*batch_size_train, 16, num_classes]) / num_classes\n",
    "        _, loss, acc = self.sess.run([self.train_op,self.cross_entropy_loss,self.accuracy],feed_dict={\n",
    "                                        self.X: batch_xs,\n",
    "                                        self.r_conv_caps1: r_conv_caps1_in,\n",
    "                                        self.r_conv_caps2: r_conv_caps2_in,\n",
    "                                        self.r_class_caps: r_class_caps_in,\n",
    "                                        self.coord_add_op_class_caps: coord_add,\n",
    "                                        self.bs: np.int32(batch_size_train),\n",
    "                                        self.Y:batch_ys})\n",
    "        return loss, acc\n",
    "    def test_acc(self, batch_xs, batch_ys, batch_size_train):\n",
    "        coord_add = get_coord_add('mnist') \n",
    "        coord_add = np.reshape(coord_add, newshape=[3 * 3, 1, 1, 2]) #data_size =3\n",
    "        coord_add = np.tile(coord_add, [batch_size_train, D, num_classes, 1])\n",
    "        r_conv_caps1_in = np.ones([5*5*batch_size_train, 72, C]) / C\n",
    "        r_conv_caps2_in = np.ones([3*3*batch_size_train, 144, D]) / D\n",
    "        r_class_caps_in = np.ones([3*3*batch_size_train, 16, num_classes]) / num_classes\n",
    "        acc = self.sess.run(self.accuracy,feed_dict={\n",
    "                                        self.X: batch_xs,\n",
    "                                        self.r_conv_caps1: r_conv_caps1_in,\n",
    "                                        self.r_conv_caps2: r_conv_caps2_in,\n",
    "                                        self.r_class_caps: r_class_caps_in,\n",
    "                                        self.coord_add_op_class_caps: coord_add,\n",
    "                                        self.bs: np.int32(batch_size_train),\n",
    "                                        self.Y:batch_ys})\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 12, 12, 8, 16)\n",
      "(?, 12, 12, 8, 1)\n",
      "(?, 12, 12, 136)\n",
      "(?, 5, 5, 136, 9) fdsggs\n",
      "5\n",
      "1 (?, 72, 17)\n",
      "output shape --------------- (?, 72, 17)\n",
      "activation shape---------------------- (?, 72, 1)\n",
      "w (1, 72, 16, 4, 4)\n",
      "w (?, 72, 16, 4, 4)\n",
      "(?, 72, 16, 16) votes shape\n",
      "Tensor(\"conv_caps1/v/tile___3/Reshape:0\", shape=(?, 72, 16, 16), dtype=float32)  = votes\n",
      "(?, 72, 16) r shape__________\n",
      "(?, 72, 16, 1) r1\n",
      "WARNING:tensorflow:From <ipython-input-4-1e1c38c2e3bb>:35: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "(?, 72, 16) ap\n",
      "(?, 72, 16, 1) r1\n",
      "(?, 16, 1) r_sum\n",
      "(?, 16, 16) cost_h\n",
      "activation (?, 16)\n",
      "3 (?, 5, 5, 16, 16)\n",
      "activation (?, 5, 5, 16, 1)\n",
      "272\n",
      "5 (?, 5, 5, 272)\n",
      "(?, 3, 3, 272, 9) fdsggs\n",
      "canv_caps2 (?, 144, 17) 3\n",
      "canv_caps2_activation (?, 144, 1) 3\n",
      "w (1, 144, 16, 4, 4)\n",
      "w (?, 144, 16, 4, 4)\n",
      "(?, 144, 16, 16) votes shape\n",
      "144 for 1\n",
      "Tensor(\"conv_caps2/v/tile___3/Reshape:0\", shape=(?, 144, 16, 16), dtype=float32)  = votes\n",
      "(?, 144, 16) r shape__________\n",
      "(?, 144, 16, 1) r1\n",
      "(?, 144, 16) ap\n",
      "(?, 144, 16, 1) r1\n",
      "(?, 16, 1) r_sum\n",
      "(?, 16, 16) cost_h\n",
      "4 (?, 16, 16)\n",
      "4 ---activation (?, 16, 1)\n",
      "w (1, 16, 10, 4, 4)\n",
      "w (?, 16, 10, 4, 4)\n",
      "(?, 16, 10, 16) votes.getshape\n",
      "(?, 16, 10, 18) coorr vote shape after  jnbfv\n",
      "_____ 16\n",
      "Tensor(\"class_caps/v/concat:0\", shape=(?, 16, 10, 18), dtype=float32)  = votes\n",
      "(?, 16, 10) r shape__________\n",
      "(?, 16, 10, 1) r1\n",
      "(?, 16, 10) ap\n",
      "(?, 16, 10, 1) r1\n",
      "(?, 10, 1) r_sum\n",
      "(?, 10, 18) cost_h\n",
      "d op (?, 3, 3, 10)\n",
      "miu  2 (?, 1, 10, 18)\n",
      "output_size_posssss (?, 1, 1, 180)\n",
      "output_size (?, 10, 18)\n",
      "shape of logits Tensor(\"output_layer/fully_connected/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "WARNING:tensorflow:From /home/cn1lab005/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Graph for Matrix Capsule is ready for training\n",
      "session started\n",
      "step-0 summary: loss= 2.322749376296997, training accuracy = 6.0, test acc = 20.0\n",
      "step-5 summary: loss= 2.3090856075286865, training accuracy = 4.0, test acc = 13.333333969116211\n",
      "step-10 summary: loss= 2.2964370250701904, training accuracy = 12.0, test acc = 6.6666669845581055\n",
      "step-15 summary: loss= 2.2986512184143066, training accuracy = 10.0, test acc = 6.6666669845581055\n",
      "step-20 summary: loss= 2.2956290245056152, training accuracy = 22.0, test acc = 13.333333969116211\n",
      "step-25 summary: loss= 2.295069694519043, training accuracy = 10.0, test acc = 3.3333334922790527\n",
      "step-30 summary: loss= 2.292463779449463, training accuracy = 8.0, test acc = 20.0\n",
      "step-35 summary: loss= 2.296738624572754, training accuracy = 14.0, test acc = 6.6666669845581055\n",
      "step-40 summary: loss= 2.2840025424957275, training accuracy = 20.0, test acc = 16.666667938232422\n",
      "step-45 summary: loss= 2.2920703887939453, training accuracy = 14.0, test acc = 6.6666669845581055\n",
      "step-50 summary: loss= 2.2827095985412598, training accuracy = 16.0, test acc = 23.33333396911621\n",
      "step-55 summary: loss= 2.288318634033203, training accuracy = 10.0, test acc = 10.0\n",
      "step-60 summary: loss= 2.276521921157837, training accuracy = 12.0, test acc = 10.0\n",
      "step-65 summary: loss= 2.2821013927459717, training accuracy = 12.0, test acc = 3.3333334922790527\n",
      "step-70 summary: loss= 2.282792568206787, training accuracy = 18.0, test acc = 13.333333969116211\n",
      "step-75 summary: loss= 2.2504019737243652, training accuracy = 20.0, test acc = 6.6666669845581055\n",
      "step-80 summary: loss= 2.2958474159240723, training accuracy = 6.0, test acc = 10.0\n",
      "step-85 summary: loss= 2.240900993347168, training accuracy = 16.0, test acc = 6.6666669845581055\n",
      "step-90 summary: loss= 2.2384958267211914, training accuracy = 16.0, test acc = 10.0\n",
      "step-95 summary: loss= 2.2394847869873047, training accuracy = 16.0, test acc = 16.666667938232422\n",
      "step-100 summary: loss= 2.2000534534454346, training accuracy = 24.0, test acc = 6.6666669845581055\n",
      "step-105 summary: loss= 2.2512121200561523, training accuracy = 12.0, test acc = 10.0\n",
      "step-110 summary: loss= 2.215330123901367, training accuracy = 14.0, test acc = 13.333333969116211\n",
      "step-115 summary: loss= 2.220721483230591, training accuracy = 12.0, test acc = 6.6666669845581055\n",
      "step-120 summary: loss= 2.242978096008301, training accuracy = 10.0, test acc = 23.33333396911621\n",
      "step-125 summary: loss= 2.21042799949646, training accuracy = 16.0, test acc = 10.0\n",
      "step-130 summary: loss= 2.1771080493927, training accuracy = 14.0, test acc = 16.666667938232422\n",
      "step-135 summary: loss= 2.1075692176818848, training accuracy = 28.0, test acc = 3.3333334922790527\n",
      "step-140 summary: loss= 2.231940269470215, training accuracy = 10.0, test acc = 6.6666669845581055\n",
      "step-145 summary: loss= 2.250185966491699, training accuracy = 4.0, test acc = 6.6666669845581055\n",
      "step-150 summary: loss= 2.2141335010528564, training accuracy = 10.0, test acc = 30.000001907348633\n",
      "step-155 summary: loss= 2.167654037475586, training accuracy = 10.0, test acc = 3.3333334922790527\n",
      "step-160 summary: loss= 2.2264504432678223, training accuracy = 12.0, test acc = 6.6666669845581055\n",
      "step-165 summary: loss= 2.1768033504486084, training accuracy = 14.0, test acc = 10.0\n",
      "step-170 summary: loss= 2.1255228519439697, training accuracy = 22.0, test acc = 10.0\n",
      "step-175 summary: loss= 2.1944100856781006, training accuracy = 16.0, test acc = 10.0\n",
      "step-180 summary: loss= 2.2151107788085938, training accuracy = 12.0, test acc = 16.666667938232422\n",
      "step-185 summary: loss= 2.1642098426818848, training accuracy = 20.0, test acc = 13.333333969116211\n",
      "step-190 summary: loss= 2.1401522159576416, training accuracy = 12.0, test acc = 10.0\n",
      "step-195 summary: loss= 2.0879716873168945, training accuracy = 18.0, test acc = 16.666667938232422\n",
      "step-200 summary: loss= 2.0637402534484863, training accuracy = 20.0, test acc = 16.666667938232422\n",
      "step-205 summary: loss= 2.2010927200317383, training accuracy = 16.0, test acc = 16.666667938232422\n",
      "step-210 summary: loss= 2.1318247318267822, training accuracy = 10.0, test acc = 13.333333969116211\n",
      "step-215 summary: loss= 2.1542351245880127, training accuracy = 20.0, test acc = 13.333333969116211\n",
      "step-220 summary: loss= 2.174729824066162, training accuracy = 8.0, test acc = 20.0\n",
      "step-225 summary: loss= 2.1424527168273926, training accuracy = 24.0, test acc = 26.666667938232422\n",
      "step-230 summary: loss= 2.0574023723602295, training accuracy = 16.0, test acc = 10.0\n",
      "step-235 summary: loss= 2.130629062652588, training accuracy = 22.0, test acc = 10.0\n",
      "step-240 summary: loss= 2.0950560569763184, training accuracy = 22.0, test acc = 26.666667938232422\n",
      "step-245 summary: loss= 2.152944326400757, training accuracy = 24.0, test acc = 30.000001907348633\n",
      "step-250 summary: loss= 2.104292631149292, training accuracy = 16.0, test acc = 26.666667938232422\n",
      "step-255 summary: loss= 2.1352782249450684, training accuracy = 18.0, test acc = 20.0\n",
      "step-260 summary: loss= 2.0547802448272705, training accuracy = 24.0, test acc = 20.0\n",
      "step-265 summary: loss= 2.0659689903259277, training accuracy = 16.0, test acc = 23.33333396911621\n",
      "step-270 summary: loss= 2.0831141471862793, training accuracy = 34.0, test acc = 33.333335876464844\n",
      "step-275 summary: loss= 2.0747313499450684, training accuracy = 30.000001907348633, test acc = 40.0\n",
      "step-280 summary: loss= 2.142277717590332, training accuracy = 32.0, test acc = 26.666667938232422\n",
      "step-285 summary: loss= 2.032501220703125, training accuracy = 32.0, test acc = 36.66666793823242\n",
      "step-290 summary: loss= 2.0237371921539307, training accuracy = 18.0, test acc = 16.666667938232422\n",
      "step-295 summary: loss= 2.064598321914673, training accuracy = 26.0, test acc = 23.33333396911621\n",
      "step-300 summary: loss= 2.053982734680176, training accuracy = 30.000001907348633, test acc = 36.66666793823242\n",
      "step-305 summary: loss= 2.031827449798584, training accuracy = 26.0, test acc = 30.000001907348633\n",
      "step-310 summary: loss= 2.045809745788574, training accuracy = 24.0, test acc = 13.333333969116211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-315 summary: loss= 1.9006478786468506, training accuracy = 32.0, test acc = 26.666667938232422\n",
      "step-320 summary: loss= 2.1093108654022217, training accuracy = 18.0, test acc = 36.66666793823242\n",
      "step-325 summary: loss= 2.0133211612701416, training accuracy = 40.0, test acc = 33.333335876464844\n",
      "step-330 summary: loss= 2.1492726802825928, training accuracy = 20.0, test acc = 33.333335876464844\n",
      "step-335 summary: loss= 1.9389210939407349, training accuracy = 22.0, test acc = 36.66666793823242\n",
      "step-340 summary: loss= 1.9050756692886353, training accuracy = 34.0, test acc = 33.333335876464844\n",
      "step-345 summary: loss= 2.114236831665039, training accuracy = 26.0, test acc = 30.000001907348633\n",
      "step-350 summary: loss= 2.024559259414673, training accuracy = 36.0, test acc = 30.000001907348633\n",
      "step-355 summary: loss= 1.9313664436340332, training accuracy = 40.0, test acc = 43.33333206176758\n",
      "step-360 summary: loss= 2.0715723037719727, training accuracy = 24.0, test acc = 20.0\n",
      "step-365 summary: loss= 2.02150559425354, training accuracy = 46.0, test acc = 43.33333206176758\n",
      "step-370 summary: loss= 1.973933458328247, training accuracy = 32.0, test acc = 53.333335876464844\n",
      "step-375 summary: loss= 1.9067977666854858, training accuracy = 40.0, test acc = 46.66666793823242\n",
      "step-380 summary: loss= 1.8215630054473877, training accuracy = 42.0, test acc = 36.66666793823242\n",
      "step-385 summary: loss= 1.6915216445922852, training accuracy = 52.0, test acc = 26.666667938232422\n",
      "step-390 summary: loss= 2.043158531188965, training accuracy = 34.0, test acc = 33.333335876464844\n",
      "step-395 summary: loss= 1.9542824029922485, training accuracy = 32.0, test acc = 46.66666793823242\n",
      "step-400 summary: loss= 1.78196382522583, training accuracy = 42.0, test acc = 40.0\n",
      "step-405 summary: loss= 1.884438157081604, training accuracy = 26.0, test acc = 36.66666793823242\n",
      "step-410 summary: loss= 1.75132417678833, training accuracy = 48.0, test acc = 30.000001907348633\n",
      "step-415 summary: loss= 1.9572213888168335, training accuracy = 24.0, test acc = 56.66666793823242\n",
      "step-420 summary: loss= 1.9810563325881958, training accuracy = 20.0, test acc = 26.666667938232422\n",
      "step-425 summary: loss= 1.624284267425537, training accuracy = 54.000003814697266, test acc = 30.000001907348633\n",
      "step-430 summary: loss= 1.9268063306808472, training accuracy = 36.0, test acc = 33.333335876464844\n",
      "step-435 summary: loss= 1.7672584056854248, training accuracy = 38.0, test acc = 13.333333969116211\n",
      "step-440 summary: loss= 1.837049126625061, training accuracy = 34.0, test acc = 53.333335876464844\n",
      "step-445 summary: loss= 1.7575438022613525, training accuracy = 32.0, test acc = 46.66666793823242\n",
      "step-450 summary: loss= 1.8419508934020996, training accuracy = 36.0, test acc = 23.33333396911621\n",
      "step-455 summary: loss= 1.7989424467086792, training accuracy = 38.0, test acc = 33.333335876464844\n",
      "step-460 summary: loss= 1.7838853597640991, training accuracy = 30.000001907348633, test acc = 40.0\n",
      "step-465 summary: loss= 2.0347962379455566, training accuracy = 26.0, test acc = 40.0\n",
      "step-470 summary: loss= 1.7539336681365967, training accuracy = 34.0, test acc = 33.333335876464844\n",
      "step-475 summary: loss= 1.7338162660598755, training accuracy = 42.0, test acc = 30.000001907348633\n",
      "step-480 summary: loss= 1.7563982009887695, training accuracy = 34.0, test acc = 30.000001907348633\n",
      "step-485 summary: loss= 1.6885353326797485, training accuracy = 42.0, test acc = 33.333335876464844\n",
      "step-490 summary: loss= 1.6966586112976074, training accuracy = 34.0, test acc = 50.0\n",
      "step-495 summary: loss= 1.8055026531219482, training accuracy = 36.0, test acc = 26.666667938232422\n",
      "step-500 summary: loss= 1.8001309633255005, training accuracy = 40.0, test acc = 46.66666793823242\n",
      "step-505 summary: loss= 1.649764895439148, training accuracy = 38.0, test acc = 36.66666793823242\n",
      "step-510 summary: loss= 1.635138750076294, training accuracy = 50.0, test acc = 36.66666793823242\n",
      "step-515 summary: loss= 1.7397565841674805, training accuracy = 34.0, test acc = 30.000001907348633\n",
      "step-520 summary: loss= 1.898969292640686, training accuracy = 24.0, test acc = 46.66666793823242\n",
      "step-525 summary: loss= 1.81715726852417, training accuracy = 26.0, test acc = 40.0\n",
      "step-530 summary: loss= 1.6813507080078125, training accuracy = 42.0, test acc = 40.0\n",
      "step-535 summary: loss= 1.6784987449645996, training accuracy = 36.0, test acc = 43.33333206176758\n",
      "step-540 summary: loss= 1.524633526802063, training accuracy = 40.0, test acc = 30.000001907348633\n",
      "step-545 summary: loss= 1.6833500862121582, training accuracy = 40.0, test acc = 40.0\n",
      "step-550 summary: loss= 1.6063358783721924, training accuracy = 38.0, test acc = 30.000001907348633\n",
      "step-555 summary: loss= 1.5713430643081665, training accuracy = 52.0, test acc = 36.66666793823242\n",
      "step-560 summary: loss= 1.6769652366638184, training accuracy = 30.000001907348633, test acc = 50.0\n",
      "step-565 summary: loss= 1.739670753479004, training accuracy = 30.000001907348633, test acc = 50.0\n",
      "step-570 summary: loss= 1.475996732711792, training accuracy = 42.0, test acc = 23.33333396911621\n",
      "step-575 summary: loss= 1.7584463357925415, training accuracy = 48.0, test acc = 20.0\n",
      "step-580 summary: loss= 1.531430721282959, training accuracy = 38.0, test acc = 26.666667938232422\n",
      "step-585 summary: loss= 1.471634864807129, training accuracy = 50.0, test acc = 50.0\n",
      "step-590 summary: loss= 1.5892324447631836, training accuracy = 48.0, test acc = 50.0\n",
      "step-595 summary: loss= 1.4455173015594482, training accuracy = 52.0, test acc = 40.0\n",
      "step-600 summary: loss= 1.4885116815567017, training accuracy = 52.0, test acc = 60.000003814697266\n",
      "step-605 summary: loss= 1.6144336462020874, training accuracy = 38.0, test acc = 40.0\n",
      "step-610 summary: loss= 1.6001231670379639, training accuracy = 34.0, test acc = 43.33333206176758\n",
      "step-615 summary: loss= 1.265398621559143, training accuracy = 56.0, test acc = 50.0\n",
      "step-620 summary: loss= 1.5802382230758667, training accuracy = 38.0, test acc = 50.0\n",
      "step-625 summary: loss= 1.299712061882019, training accuracy = 52.0, test acc = 53.333335876464844\n",
      "step-630 summary: loss= 1.2920335531234741, training accuracy = 56.0, test acc = 60.000003814697266\n",
      "step-635 summary: loss= 1.4713209867477417, training accuracy = 56.0, test acc = 63.33333206176758\n",
      "step-640 summary: loss= 1.1741328239440918, training accuracy = 64.0, test acc = 40.0\n",
      "step-645 summary: loss= 1.3625617027282715, training accuracy = 48.0, test acc = 43.33333206176758\n",
      "step-650 summary: loss= 1.339155912399292, training accuracy = 60.000003814697266, test acc = 50.0\n",
      "step-655 summary: loss= 1.5829828977584839, training accuracy = 56.0, test acc = 40.0\n",
      "step-660 summary: loss= 1.446547508239746, training accuracy = 40.0, test acc = 60.000003814697266\n",
      "step-665 summary: loss= 1.2780603170394897, training accuracy = 72.0, test acc = 60.000003814697266\n",
      "step-670 summary: loss= 1.3523751497268677, training accuracy = 58.0, test acc = 70.0\n",
      "step-675 summary: loss= 1.3861627578735352, training accuracy = 50.0, test acc = 63.33333206176758\n",
      "step-680 summary: loss= 1.2804086208343506, training accuracy = 58.0, test acc = 66.66667175292969\n",
      "step-685 summary: loss= 1.0127067565917969, training accuracy = 68.0, test acc = 63.33333206176758\n",
      "step-690 summary: loss= 1.4271222352981567, training accuracy = 62.0, test acc = 56.66666793823242\n",
      "step-695 summary: loss= 1.4300949573516846, training accuracy = 42.0, test acc = 46.66666793823242\n",
      "step-700 summary: loss= 1.1093676090240479, training accuracy = 62.0, test acc = 56.66666793823242\n",
      "step-705 summary: loss= 1.137468695640564, training accuracy = 68.0, test acc = 80.0\n",
      "step-710 summary: loss= 1.1230230331420898, training accuracy = 72.0, test acc = 50.0\n",
      "step-715 summary: loss= 1.2814209461212158, training accuracy = 62.0, test acc = 50.0\n",
      "step-720 summary: loss= 1.2827578783035278, training accuracy = 56.0, test acc = 73.33333587646484\n",
      "step-725 summary: loss= 0.954243004322052, training accuracy = 74.0, test acc = 66.66667175292969\n",
      "step-730 summary: loss= 1.081546425819397, training accuracy = 68.0, test acc = 53.333335876464844\n",
      "step-735 summary: loss= 1.109248399734497, training accuracy = 68.0, test acc = 73.33333587646484\n",
      "step-740 summary: loss= 0.9254883527755737, training accuracy = 78.0, test acc = 76.66666412353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-745 summary: loss= 1.0752816200256348, training accuracy = 70.0, test acc = 76.66666412353516\n",
      "step-750 summary: loss= 0.9351963996887207, training accuracy = 76.0, test acc = 63.33333206176758\n",
      "step-755 summary: loss= 0.9968814253807068, training accuracy = 68.0, test acc = 70.0\n",
      "step-760 summary: loss= 0.8309645652770996, training accuracy = 80.0, test acc = 73.33333587646484\n",
      "step-765 summary: loss= 1.0568162202835083, training accuracy = 66.0, test acc = 76.66666412353516\n",
      "step-770 summary: loss= 1.02456796169281, training accuracy = 68.0, test acc = 63.33333206176758\n",
      "step-775 summary: loss= 1.1860712766647339, training accuracy = 58.0, test acc = 76.66666412353516\n",
      "step-780 summary: loss= 1.0909037590026855, training accuracy = 60.000003814697266, test acc = 76.66666412353516\n",
      "step-785 summary: loss= 0.798025369644165, training accuracy = 92.0, test acc = 80.0\n",
      "step-790 summary: loss= 0.8997924327850342, training accuracy = 80.0, test acc = 86.66666412353516\n",
      "step-795 summary: loss= 1.051666259765625, training accuracy = 68.0, test acc = 83.33332824707031\n",
      "step-800 summary: loss= 0.8757013082504272, training accuracy = 74.0, test acc = 73.33333587646484\n",
      "step-805 summary: loss= 0.9422188401222229, training accuracy = 74.0, test acc = 60.000003814697266\n",
      "step-810 summary: loss= 0.7534613013267517, training accuracy = 80.0, test acc = 63.33333206176758\n",
      "step-815 summary: loss= 0.7874176502227783, training accuracy = 80.0, test acc = 73.33333587646484\n",
      "step-820 summary: loss= 0.771808385848999, training accuracy = 78.0, test acc = 73.33333587646484\n",
      "step-825 summary: loss= 0.7622590661048889, training accuracy = 80.0, test acc = 70.0\n",
      "step-830 summary: loss= 0.8207188248634338, training accuracy = 66.0, test acc = 60.000003814697266\n",
      "step-835 summary: loss= 0.944701075553894, training accuracy = 72.0, test acc = 73.33333587646484\n",
      "step-840 summary: loss= 1.153895616531372, training accuracy = 70.0, test acc = 73.33333587646484\n",
      "step-845 summary: loss= 0.7348518967628479, training accuracy = 70.0, test acc = 76.66666412353516\n",
      "step-850 summary: loss= 0.6299616098403931, training accuracy = 88.0, test acc = 73.33333587646484\n",
      "step-855 summary: loss= 0.6047172546386719, training accuracy = 86.0, test acc = 70.0\n",
      "step-860 summary: loss= 0.8414495587348938, training accuracy = 70.0, test acc = 83.33332824707031\n",
      "step-865 summary: loss= 0.823222815990448, training accuracy = 72.0, test acc = 73.33333587646484\n",
      "step-870 summary: loss= 0.6327572464942932, training accuracy = 84.0, test acc = 66.66667175292969\n",
      "step-875 summary: loss= 0.8651970028877258, training accuracy = 70.0, test acc = 80.0\n",
      "step-880 summary: loss= 0.6471825242042542, training accuracy = 86.0, test acc = 80.0\n",
      "step-885 summary: loss= 0.607164204120636, training accuracy = 78.0, test acc = 83.33332824707031\n",
      "step-890 summary: loss= 0.8915339112281799, training accuracy = 70.0, test acc = 80.0\n",
      "step-895 summary: loss= 0.7138993144035339, training accuracy = 84.0, test acc = 80.0\n",
      "step-900 summary: loss= 0.6869886517524719, training accuracy = 80.0, test acc = 86.66666412353516\n",
      "step-905 summary: loss= 0.6548104286193848, training accuracy = 84.0, test acc = 90.0\n",
      "step-910 summary: loss= 0.7365242838859558, training accuracy = 80.0, test acc = 83.33332824707031\n",
      "step-915 summary: loss= 0.6552581787109375, training accuracy = 88.0, test acc = 76.66666412353516\n",
      "step-920 summary: loss= 0.6748242378234863, training accuracy = 80.0, test acc = 83.33332824707031\n",
      "step-925 summary: loss= 0.6818526387214661, training accuracy = 86.0, test acc = 70.0\n",
      "step-930 summary: loss= 0.47384777665138245, training accuracy = 90.0, test acc = 80.0\n",
      "step-935 summary: loss= 0.5214821696281433, training accuracy = 86.0, test acc = 86.66666412353516\n",
      "step-940 summary: loss= 0.44474002718925476, training accuracy = 94.0, test acc = 80.0\n",
      "step-945 summary: loss= 0.7469544410705566, training accuracy = 76.0, test acc = 86.66666412353516\n",
      "step-950 summary: loss= 0.5048131346702576, training accuracy = 86.0, test acc = 90.0\n",
      "step-955 summary: loss= 0.3804705739021301, training accuracy = 94.0, test acc = 73.33333587646484\n",
      "step-960 summary: loss= 0.5375751256942749, training accuracy = 84.0, test acc = 83.33332824707031\n",
      "step-965 summary: loss= 0.664825975894928, training accuracy = 80.0, test acc = 76.66666412353516\n",
      "step-970 summary: loss= 0.44366875290870667, training accuracy = 88.0, test acc = 83.33332824707031\n",
      "step-975 summary: loss= 0.8219031691551208, training accuracy = 72.0, test acc = 83.33332824707031\n",
      "step-980 summary: loss= 0.6021487712860107, training accuracy = 86.0, test acc = 76.66666412353516\n",
      "step-985 summary: loss= 0.48636332154273987, training accuracy = 90.0, test acc = 73.33333587646484\n",
      "step-990 summary: loss= 0.5954680442810059, training accuracy = 88.0, test acc = 86.66666412353516\n",
      "step-995 summary: loss= 0.7088759541511536, training accuracy = 82.0, test acc = 76.66666412353516\n",
      "step-1000 summary: loss= 0.5511261820793152, training accuracy = 82.0, test acc = 86.66666412353516\n",
      "step-1005 summary: loss= 0.5037487149238586, training accuracy = 88.0, test acc = 76.66666412353516\n",
      "step-1010 summary: loss= 0.5471091270446777, training accuracy = 88.0, test acc = 76.66666412353516\n",
      "step-1015 summary: loss= 0.40742504596710205, training accuracy = 92.0, test acc = 90.0\n",
      "step-1020 summary: loss= 0.3978266417980194, training accuracy = 90.0, test acc = 80.0\n",
      "step-1025 summary: loss= 0.620015561580658, training accuracy = 80.0, test acc = 76.66666412353516\n",
      "step-1030 summary: loss= 0.5553922653198242, training accuracy = 82.0, test acc = 83.33332824707031\n",
      "step-1035 summary: loss= 0.6066272854804993, training accuracy = 76.0, test acc = 86.66666412353516\n",
      "step-1040 summary: loss= 0.6620717644691467, training accuracy = 84.0, test acc = 80.0\n",
      "step-1045 summary: loss= 0.5563392043113708, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1050 summary: loss= 0.35943639278411865, training accuracy = 90.0, test acc = 76.66666412353516\n",
      "step-1055 summary: loss= 0.4808143675327301, training accuracy = 84.0, test acc = 83.33332824707031\n",
      "step-1060 summary: loss= 0.526211678981781, training accuracy = 82.0, test acc = 76.66666412353516\n",
      "step-1065 summary: loss= 0.4519222676753998, training accuracy = 84.0, test acc = 73.33333587646484\n",
      "step-1070 summary: loss= 0.35325661301612854, training accuracy = 96.0, test acc = 83.33332824707031\n",
      "step-1075 summary: loss= 0.42802947759628296, training accuracy = 88.0, test acc = 83.33332824707031\n",
      "step-1080 summary: loss= 0.42746245861053467, training accuracy = 86.0, test acc = 76.66666412353516\n",
      "step-1085 summary: loss= 0.5186415910720825, training accuracy = 84.0, test acc = 90.0\n",
      "step-1090 summary: loss= 0.43479105830192566, training accuracy = 90.0, test acc = 90.0\n",
      "step-1095 summary: loss= 0.5119103789329529, training accuracy = 84.0, test acc = 93.33333587646484\n",
      "step-1100 summary: loss= 0.39187896251678467, training accuracy = 86.0, test acc = 90.0\n",
      "step-1105 summary: loss= 0.5036380887031555, training accuracy = 84.0, test acc = 93.33333587646484\n",
      "step-1110 summary: loss= 0.6679388284683228, training accuracy = 74.0, test acc = 80.0\n",
      "step-1115 summary: loss= 0.6705730557441711, training accuracy = 86.0, test acc = 83.33332824707031\n",
      "step-1120 summary: loss= 0.39802977442741394, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1125 summary: loss= 0.5142152905464172, training accuracy = 84.0, test acc = 90.0\n",
      "step-1130 summary: loss= 0.7379464507102966, training accuracy = 84.0, test acc = 80.0\n",
      "step-1135 summary: loss= 0.5599022507667542, training accuracy = 84.0, test acc = 96.66666412353516\n",
      "step-1140 summary: loss= 0.480692058801651, training accuracy = 84.0, test acc = 100.0\n",
      "step-1145 summary: loss= 0.44369015097618103, training accuracy = 88.0, test acc = 83.33332824707031\n",
      "step-1150 summary: loss= 0.5244734883308411, training accuracy = 82.0, test acc = 90.0\n",
      "step-1155 summary: loss= 0.6034032106399536, training accuracy = 86.0, test acc = 90.0\n",
      "step-1160 summary: loss= 0.6691848039627075, training accuracy = 80.0, test acc = 93.33333587646484\n",
      "step-1165 summary: loss= 0.6237371563911438, training accuracy = 84.0, test acc = 90.0\n",
      "step-1170 summary: loss= 0.305195689201355, training accuracy = 96.0, test acc = 90.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-1175 summary: loss= 0.6684384346008301, training accuracy = 72.0, test acc = 90.0\n",
      "step-1180 summary: loss= 0.39449751377105713, training accuracy = 88.0, test acc = 90.0\n",
      "step-1185 summary: loss= 0.3045433759689331, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1190 summary: loss= 0.3401741683483124, training accuracy = 86.0, test acc = 73.33333587646484\n",
      "step-1195 summary: loss= 0.3670032024383545, training accuracy = 86.0, test acc = 80.0\n",
      "step-1200 summary: loss= 0.6861773133277893, training accuracy = 82.0, test acc = 86.66666412353516\n",
      "step-1205 summary: loss= 0.6039700508117676, training accuracy = 88.0, test acc = 90.0\n",
      "step-1210 summary: loss= 0.5501613020896912, training accuracy = 78.0, test acc = 90.0\n",
      "step-1215 summary: loss= 0.4578954577445984, training accuracy = 86.0, test acc = 86.66666412353516\n",
      "step-1220 summary: loss= 0.362844318151474, training accuracy = 92.0, test acc = 90.0\n",
      "step-1225 summary: loss= 0.3221363127231598, training accuracy = 94.0, test acc = 80.0\n",
      "step-1230 summary: loss= 0.40769249200820923, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1235 summary: loss= 0.3969840705394745, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1240 summary: loss= 0.4097151458263397, training accuracy = 90.0, test acc = 90.0\n",
      "step-1245 summary: loss= 0.244217649102211, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-1250 summary: loss= 0.28342390060424805, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1255 summary: loss= 0.32228800654411316, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-1260 summary: loss= 0.3097015619277954, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1265 summary: loss= 0.2967866063117981, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1270 summary: loss= 0.37209171056747437, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1275 summary: loss= 0.3508041501045227, training accuracy = 86.0, test acc = 76.66666412353516\n",
      "step-1280 summary: loss= 0.4062580168247223, training accuracy = 88.0, test acc = 90.0\n",
      "step-1285 summary: loss= 0.40137648582458496, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1290 summary: loss= 0.2218819409608841, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1295 summary: loss= 0.3748733103275299, training accuracy = 90.0, test acc = 90.0\n",
      "step-1300 summary: loss= 0.5129536986351013, training accuracy = 80.0, test acc = 83.33332824707031\n",
      "step-1305 summary: loss= 0.35836929082870483, training accuracy = 90.0, test acc = 90.0\n",
      "step-1310 summary: loss= 0.2750735282897949, training accuracy = 96.0, test acc = 100.0\n",
      "step-1315 summary: loss= 0.28907206654548645, training accuracy = 92.0, test acc = 86.66666412353516\n",
      "step-1320 summary: loss= 0.4740792214870453, training accuracy = 88.0, test acc = 100.0\n",
      "step-1325 summary: loss= 0.5040318369865417, training accuracy = 90.0, test acc = 90.0\n",
      "step-1330 summary: loss= 0.3619951009750366, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-1335 summary: loss= 0.23778177797794342, training accuracy = 92.0, test acc = 90.0\n",
      "step-1340 summary: loss= 0.3844006061553955, training accuracy = 88.0, test acc = 93.33333587646484\n",
      "step-1345 summary: loss= 0.34477606415748596, training accuracy = 90.0, test acc = 100.0\n",
      "step-1350 summary: loss= 0.3356301486492157, training accuracy = 88.0, test acc = 93.33333587646484\n",
      "step-1355 summary: loss= 0.3691072165966034, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1360 summary: loss= 0.4713943898677826, training accuracy = 84.0, test acc = 100.0\n",
      "step-1365 summary: loss= 0.8612008690834045, training accuracy = 78.0, test acc = 86.66666412353516\n",
      "step-1370 summary: loss= 0.3622966408729553, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1375 summary: loss= 0.29574546217918396, training accuracy = 90.0, test acc = 90.0\n",
      "step-1380 summary: loss= 0.14408190548419952, training accuracy = 100.0, test acc = 83.33332824707031\n",
      "step-1385 summary: loss= 0.14795760810375214, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1390 summary: loss= 0.1648213416337967, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1395 summary: loss= 0.23678931593894958, training accuracy = 94.0, test acc = 90.0\n",
      "step-1400 summary: loss= 0.23661699891090393, training accuracy = 96.0, test acc = 76.66666412353516\n",
      "step-1405 summary: loss= 0.2910034656524658, training accuracy = 88.0, test acc = 90.0\n",
      "step-1410 summary: loss= 0.5234148502349854, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1415 summary: loss= 0.46812424063682556, training accuracy = 88.0, test acc = 96.66666412353516\n",
      "step-1420 summary: loss= 0.30825626850128174, training accuracy = 88.0, test acc = 96.66666412353516\n",
      "step-1425 summary: loss= 0.3124849200248718, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-1430 summary: loss= 0.14640440046787262, training accuracy = 100.0, test acc = 93.33333587646484\n",
      "step-1435 summary: loss= 0.2910403907299042, training accuracy = 90.0, test acc = 90.0\n",
      "step-1440 summary: loss= 0.2958565354347229, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1445 summary: loss= 0.40964505076408386, training accuracy = 92.0, test acc = 83.33332824707031\n",
      "step-1450 summary: loss= 0.26206645369529724, training accuracy = 96.0, test acc = 90.0\n",
      "step-1455 summary: loss= 0.3025570511817932, training accuracy = 88.0, test acc = 96.66666412353516\n",
      "step-1460 summary: loss= 0.40040579438209534, training accuracy = 84.0, test acc = 96.66666412353516\n",
      "step-1465 summary: loss= 0.27299973368644714, training accuracy = 92.0, test acc = 86.66666412353516\n",
      "step-1470 summary: loss= 0.2514950633049011, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1475 summary: loss= 0.24535928666591644, training accuracy = 92.0, test acc = 90.0\n",
      "step-1480 summary: loss= 0.3312698006629944, training accuracy = 94.0, test acc = 86.66666412353516\n",
      "step-1485 summary: loss= 0.2508617639541626, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1490 summary: loss= 0.3517625033855438, training accuracy = 86.0, test acc = 93.33333587646484\n",
      "step-1495 summary: loss= 0.2623008191585541, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-1500 summary: loss= 0.3433327376842499, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1505 summary: loss= 0.24273163080215454, training accuracy = 94.0, test acc = 86.66666412353516\n",
      "step-1510 summary: loss= 0.34795913100242615, training accuracy = 88.0, test acc = 86.66666412353516\n",
      "step-1515 summary: loss= 0.25994810461997986, training accuracy = 94.0, test acc = 83.33332824707031\n",
      "step-1520 summary: loss= 0.675861656665802, training accuracy = 82.0, test acc = 86.66666412353516\n",
      "step-1525 summary: loss= 0.22652550041675568, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1530 summary: loss= 0.22491365671157837, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1535 summary: loss= 0.1482732594013214, training accuracy = 98.0, test acc = 93.33333587646484\n",
      "step-1540 summary: loss= 0.09780634939670563, training accuracy = 98.0, test acc = 90.0\n",
      "step-1545 summary: loss= 0.527583658695221, training accuracy = 90.0, test acc = 90.0\n",
      "step-1550 summary: loss= 0.3356964588165283, training accuracy = 88.0, test acc = 90.0\n",
      "step-1555 summary: loss= 0.24405337870121002, training accuracy = 96.0, test acc = 90.0\n",
      "step-1560 summary: loss= 0.15871714055538177, training accuracy = 100.0, test acc = 100.0\n",
      "step-1565 summary: loss= 0.23608914017677307, training accuracy = 90.0, test acc = 90.0\n",
      "step-1570 summary: loss= 0.5774189829826355, training accuracy = 88.0, test acc = 100.0\n",
      "step-1575 summary: loss= 0.3612675070762634, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1580 summary: loss= 0.5255742073059082, training accuracy = 88.0, test acc = 90.0\n",
      "step-1585 summary: loss= 0.3868011236190796, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1590 summary: loss= 0.2529449760913849, training accuracy = 94.0, test acc = 83.33332824707031\n",
      "step-1595 summary: loss= 0.5602372288703918, training accuracy = 88.0, test acc = 90.0\n",
      "step-1600 summary: loss= 0.16157856583595276, training accuracy = 94.0, test acc = 96.66666412353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-1605 summary: loss= 0.4545876979827881, training accuracy = 86.0, test acc = 90.0\n",
      "step-1610 summary: loss= 0.3651581108570099, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1615 summary: loss= 0.47842612862586975, training accuracy = 84.0, test acc = 90.0\n",
      "step-1620 summary: loss= 0.3884197175502777, training accuracy = 86.0, test acc = 93.33333587646484\n",
      "step-1625 summary: loss= 0.23159103095531464, training accuracy = 88.0, test acc = 93.33333587646484\n",
      "step-1630 summary: loss= 0.3055935204029083, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1635 summary: loss= 0.35574501752853394, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1640 summary: loss= 0.2539653480052948, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1645 summary: loss= 0.2545824944972992, training accuracy = 96.0, test acc = 86.66666412353516\n",
      "step-1650 summary: loss= 0.6332545280456543, training accuracy = 82.0, test acc = 93.33333587646484\n",
      "step-1655 summary: loss= 0.3853749930858612, training accuracy = 92.0, test acc = 83.33332824707031\n",
      "step-1660 summary: loss= 0.35907283425331116, training accuracy = 90.0, test acc = 83.33332824707031\n",
      "step-1665 summary: loss= 0.4944467842578888, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1670 summary: loss= 0.43571633100509644, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1675 summary: loss= 0.45916083455085754, training accuracy = 84.0, test acc = 96.66666412353516\n",
      "step-1680 summary: loss= 0.229887917637825, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1685 summary: loss= 0.21399421989917755, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1690 summary: loss= 0.5292330384254456, training accuracy = 88.0, test acc = 93.33333587646484\n",
      "step-1695 summary: loss= 0.12936937808990479, training accuracy = 98.0, test acc = 83.33332824707031\n",
      "step-1700 summary: loss= 0.13757926225662231, training accuracy = 98.0, test acc = 83.33332824707031\n",
      "step-1705 summary: loss= 0.33578622341156006, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1710 summary: loss= 0.28724876046180725, training accuracy = 88.0, test acc = 86.66666412353516\n",
      "step-1715 summary: loss= 0.23516513407230377, training accuracy = 94.0, test acc = 90.0\n",
      "step-1720 summary: loss= 0.37026363611221313, training accuracy = 84.0, test acc = 86.66666412353516\n",
      "step-1725 summary: loss= 0.28624504804611206, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1730 summary: loss= 0.22136333584785461, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1735 summary: loss= 0.21056383848190308, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1740 summary: loss= 0.2293529063463211, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1745 summary: loss= 0.19843174517154694, training accuracy = 94.0, test acc = 100.0\n",
      "step-1750 summary: loss= 0.22588452696800232, training accuracy = 90.0, test acc = 90.0\n",
      "step-1755 summary: loss= 0.2731870412826538, training accuracy = 94.0, test acc = 100.0\n",
      "step-1760 summary: loss= 0.2519601583480835, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1765 summary: loss= 0.27809110283851624, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1770 summary: loss= 0.31849777698516846, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1775 summary: loss= 0.3196449279785156, training accuracy = 86.0, test acc = 96.66666412353516\n",
      "step-1780 summary: loss= 0.32147786021232605, training accuracy = 86.0, test acc = 90.0\n",
      "step-1785 summary: loss= 0.356964647769928, training accuracy = 88.0, test acc = 93.33333587646484\n",
      "step-1790 summary: loss= 0.15026581287384033, training accuracy = 92.0, test acc = 86.66666412353516\n",
      "step-1795 summary: loss= 0.24313236773014069, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1800 summary: loss= 0.1905837506055832, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1805 summary: loss= 0.3523200750350952, training accuracy = 88.0, test acc = 73.33333587646484\n",
      "step-1810 summary: loss= 0.38961857557296753, training accuracy = 88.0, test acc = 83.33332824707031\n",
      "step-1815 summary: loss= 0.2747533321380615, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1820 summary: loss= 0.3222767114639282, training accuracy = 88.0, test acc = 96.66666412353516\n",
      "step-1825 summary: loss= 0.16847868263721466, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-1830 summary: loss= 0.28985390067100525, training accuracy = 92.0, test acc = 100.0\n",
      "step-1835 summary: loss= 0.2432764768600464, training accuracy = 90.0, test acc = 90.0\n",
      "step-1840 summary: loss= 0.35343289375305176, training accuracy = 94.0, test acc = 76.66666412353516\n",
      "step-1845 summary: loss= 0.1967553198337555, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1850 summary: loss= 0.19314634799957275, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1855 summary: loss= 0.4892040193080902, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1860 summary: loss= 0.2701912820339203, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1865 summary: loss= 0.18952548503875732, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-1870 summary: loss= 0.2951830327510834, training accuracy = 88.0, test acc = 86.66666412353516\n",
      "step-1875 summary: loss= 0.17396661639213562, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1880 summary: loss= 0.10504460334777832, training accuracy = 98.0, test acc = 93.33333587646484\n",
      "step-1885 summary: loss= 0.18856213986873627, training accuracy = 96.0, test acc = 90.0\n",
      "step-1890 summary: loss= 0.20279918611049652, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-1895 summary: loss= 0.20068775117397308, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-1900 summary: loss= 0.3981432616710663, training accuracy = 88.0, test acc = 83.33332824707031\n",
      "step-1905 summary: loss= 0.22716346383094788, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1910 summary: loss= 0.09018485248088837, training accuracy = 100.0, test acc = 93.33333587646484\n",
      "step-1915 summary: loss= 0.35004371404647827, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1920 summary: loss= 0.2714152932167053, training accuracy = 92.0, test acc = 90.0\n",
      "step-1925 summary: loss= 0.21563903987407684, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-1930 summary: loss= 0.1464819759130478, training accuracy = 94.0, test acc = 86.66666412353516\n",
      "step-1935 summary: loss= 0.4626629948616028, training accuracy = 92.0, test acc = 83.33332824707031\n",
      "step-1940 summary: loss= 0.31574803590774536, training accuracy = 94.0, test acc = 83.33332824707031\n",
      "step-1945 summary: loss= 0.2890719175338745, training accuracy = 90.0, test acc = 93.33333587646484\n",
      "step-1950 summary: loss= 0.25645753741264343, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-1955 summary: loss= 0.24161571264266968, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-1960 summary: loss= 0.40840426087379456, training accuracy = 84.0, test acc = 86.66666412353516\n",
      "step-1965 summary: loss= 0.12190297245979309, training accuracy = 98.0, test acc = 83.33332824707031\n",
      "step-1970 summary: loss= 0.14235033094882965, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-1975 summary: loss= 0.14458614587783813, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-1980 summary: loss= 0.3800199031829834, training accuracy = 86.0, test acc = 93.33333587646484\n",
      "step-1985 summary: loss= 0.2941564619541168, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-1990 summary: loss= 0.15733711421489716, training accuracy = 98.0, test acc = 86.66666412353516\n",
      "step-1995 summary: loss= 0.27161705493927, training accuracy = 88.0, test acc = 96.66666412353516\n",
      "step-2000 summary: loss= 0.4405238628387451, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-2005 summary: loss= 0.17799273133277893, training accuracy = 96.0, test acc = 100.0\n",
      "step-2010 summary: loss= 0.30596089363098145, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-2015 summary: loss= 0.2544398307800293, training accuracy = 94.0, test acc = 96.66666412353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step-2020 summary: loss= 0.22325879335403442, training accuracy = 94.0, test acc = 83.33332824707031\n",
      "step-2025 summary: loss= 0.19846881926059723, training accuracy = 92.0, test acc = 83.33332824707031\n",
      "step-2030 summary: loss= 0.31420233845710754, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-2035 summary: loss= 0.3402603268623352, training accuracy = 88.0, test acc = 96.66666412353516\n",
      "step-2040 summary: loss= 0.30355948209762573, training accuracy = 90.0, test acc = 90.0\n",
      "step-2045 summary: loss= 0.15601210296154022, training accuracy = 96.0, test acc = 100.0\n",
      "step-2050 summary: loss= 0.2593457102775574, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-2055 summary: loss= 0.2946973443031311, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-2060 summary: loss= 0.33413010835647583, training accuracy = 90.0, test acc = 96.66666412353516\n",
      "step-2065 summary: loss= 0.17819887399673462, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-2070 summary: loss= 0.21012286841869354, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2075 summary: loss= 0.09709656983613968, training accuracy = 98.0, test acc = 96.66666412353516\n",
      "step-2080 summary: loss= 0.2319614440202713, training accuracy = 90.0, test acc = 86.66666412353516\n",
      "step-2085 summary: loss= 0.213365375995636, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-2090 summary: loss= 0.07084430754184723, training accuracy = 100.0, test acc = 93.33333587646484\n",
      "step-2095 summary: loss= 0.09898534417152405, training accuracy = 98.0, test acc = 96.66666412353516\n",
      "step-2100 summary: loss= 0.1618652492761612, training accuracy = 98.0, test acc = 90.0\n",
      "step-2105 summary: loss= 0.3062252998352051, training accuracy = 88.0, test acc = 100.0\n",
      "step-2110 summary: loss= 0.10819853842258453, training accuracy = 98.0, test acc = 100.0\n",
      "step-2115 summary: loss= 0.22794000804424286, training accuracy = 92.0, test acc = 100.0\n",
      "step-2120 summary: loss= 0.21744641661643982, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2125 summary: loss= 0.25738048553466797, training accuracy = 92.0, test acc = 100.0\n",
      "step-2130 summary: loss= 0.1752367466688156, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-2135 summary: loss= 0.17600508034229279, training accuracy = 96.0, test acc = 90.0\n",
      "step-2140 summary: loss= 0.12278644740581512, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2145 summary: loss= 0.21406754851341248, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-2150 summary: loss= 0.10582080483436584, training accuracy = 100.0, test acc = 93.33333587646484\n",
      "step-2155 summary: loss= 0.19569438695907593, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-2160 summary: loss= 0.2092127799987793, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2165 summary: loss= 0.18552617728710175, training accuracy = 94.0, test acc = 100.0\n",
      "step-2170 summary: loss= 0.09800328314304352, training accuracy = 100.0, test acc = 96.66666412353516\n",
      "step-2175 summary: loss= 0.21293626725673676, training accuracy = 92.0, test acc = 90.0\n",
      "step-2180 summary: loss= 0.27364033460617065, training accuracy = 92.0, test acc = 90.0\n",
      "step-2185 summary: loss= 0.15461842715740204, training accuracy = 96.0, test acc = 83.33332824707031\n",
      "step-2190 summary: loss= 0.11031869798898697, training accuracy = 98.0, test acc = 93.33333587646484\n",
      "step-2195 summary: loss= 0.2834891080856323, training accuracy = 96.0, test acc = 90.0\n",
      "step-2200 summary: loss= 0.06613455712795258, training accuracy = 100.0, test acc = 96.66666412353516\n",
      "step-2205 summary: loss= 0.2507363557815552, training accuracy = 92.0, test acc = 90.0\n",
      "step-2210 summary: loss= 0.2173183411359787, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2215 summary: loss= 0.362239807844162, training accuracy = 86.0, test acc = 90.0\n",
      "step-2220 summary: loss= 0.26837024092674255, training accuracy = 92.0, test acc = 90.0\n",
      "step-2225 summary: loss= 0.36931365728378296, training accuracy = 88.0, test acc = 90.0\n",
      "step-2230 summary: loss= 0.25258028507232666, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2235 summary: loss= 0.1500036120414734, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-2240 summary: loss= 0.2533318102359772, training accuracy = 90.0, test acc = 100.0\n",
      "step-2245 summary: loss= 0.12696941196918488, training accuracy = 96.0, test acc = 90.0\n",
      "step-2250 summary: loss= 0.12568369507789612, training accuracy = 100.0, test acc = 93.33333587646484\n",
      "step-2255 summary: loss= 0.2816612720489502, training accuracy = 90.0, test acc = 100.0\n",
      "step-2260 summary: loss= 0.13323763012886047, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2265 summary: loss= 0.08026213943958282, training accuracy = 96.0, test acc = 80.0\n",
      "step-2270 summary: loss= 0.24182085692882538, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2275 summary: loss= 0.16934692859649658, training accuracy = 94.0, test acc = 96.66666412353516\n",
      "step-2280 summary: loss= 0.07938921451568604, training accuracy = 100.0, test acc = 96.66666412353516\n",
      "step-2285 summary: loss= 0.14623965322971344, training accuracy = 98.0, test acc = 96.66666412353516\n",
      "step-2290 summary: loss= 0.3684206008911133, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2295 summary: loss= 0.11609921604394913, training accuracy = 96.0, test acc = 86.66666412353516\n",
      "step-2300 summary: loss= 0.19324903190135956, training accuracy = 96.0, test acc = 90.0\n",
      "step-2305 summary: loss= 0.11188048124313354, training accuracy = 98.0, test acc = 93.33333587646484\n",
      "step-2310 summary: loss= 0.2287973165512085, training accuracy = 98.0, test acc = 96.66666412353516\n",
      "step-2315 summary: loss= 0.2026907354593277, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2320 summary: loss= 0.08641356229782104, training accuracy = 100.0, test acc = 100.0\n",
      "step-2325 summary: loss= 0.155079647898674, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2330 summary: loss= 0.11468035727739334, training accuracy = 100.0, test acc = 93.33333587646484\n",
      "step-2335 summary: loss= 0.1627836376428604, training accuracy = 94.0, test acc = 100.0\n",
      "step-2340 summary: loss= 0.24790199100971222, training accuracy = 94.0, test acc = 90.0\n",
      "step-2345 summary: loss= 0.43336811661720276, training accuracy = 86.0, test acc = 90.0\n",
      "step-2350 summary: loss= 0.13893313705921173, training accuracy = 96.0, test acc = 90.0\n",
      "step-2355 summary: loss= 0.21877260506153107, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-2360 summary: loss= 0.11610646545886993, training accuracy = 98.0, test acc = 96.66666412353516\n",
      "step-2365 summary: loss= 0.2371489703655243, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-2370 summary: loss= 0.25043225288391113, training accuracy = 92.0, test acc = 86.66666412353516\n",
      "step-2375 summary: loss= 0.2678084373474121, training accuracy = 92.0, test acc = 86.66666412353516\n",
      "step-2380 summary: loss= 0.19667822122573853, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-2385 summary: loss= 0.13849876821041107, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2390 summary: loss= 0.2936779856681824, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2395 summary: loss= 0.22098182141780853, training accuracy = 92.0, test acc = 93.33333587646484\n",
      "step-2400 summary: loss= 0.16254295408725739, training accuracy = 94.0, test acc = 93.33333587646484\n",
      "step-2405 summary: loss= 0.11899976432323456, training accuracy = 98.0, test acc = 100.0\n",
      "step-2410 summary: loss= 0.10819222778081894, training accuracy = 96.0, test acc = 100.0\n",
      "step-2415 summary: loss= 0.25268620252609253, training accuracy = 92.0, test acc = 90.0\n",
      "step-2420 summary: loss= 0.22109459340572357, training accuracy = 92.0, test acc = 86.66666412353516\n",
      "step-2425 summary: loss= 0.24367067217826843, training accuracy = 96.0, test acc = 93.33333587646484\n",
      "step-2430 summary: loss= 0.16512876749038696, training accuracy = 96.0, test acc = 96.66666412353516\n",
      "step-2435 summary: loss= 0.11368362605571747, training accuracy = 98.0, test acc = 90.0\n",
      "step-2440 summary: loss= 0.2455780953168869, training accuracy = 92.0, test acc = 96.66666412353516\n",
      "step-2445 summary: loss= 0.32633641362190247, training accuracy = 90.0, test acc = 100.0\n"
     ]
    }
   ],
   "source": [
    "model = MatrixCapsule()\n",
    "print(\"session started\")\n",
    "batch_size_train= 50\n",
    "batch_size_test = 30\n",
    "n_itrs = 3000\n",
    "for step in range(n_itrs):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size_train)\n",
    "    batch_xs = batch_xs.reshape(batch_size_train, 28, 28,1)\n",
    "    batch_ys = batch_ys.reshape(batch_size_train, 10)\n",
    "    loss, acc =  model.train(batch_xs, batch_ys, batch_size_train)\n",
    "    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
    "    #print(step)\n",
    "    if (step % 5 == 0):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size_test)\n",
    "        batch_xs = batch_xs.reshape(batch_size_test, 28, 28,1)\n",
    "        batch_ys = batch_ys.reshape(batch_size_test, 10)\n",
    "        tac = model.test_acc(batch_xs, batch_ys, batch_size_test)\n",
    "        print(\"step-{} summary: loss= {}, training accuracy = {}, test acc = {}\".format(step, loss, acc, tac))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
